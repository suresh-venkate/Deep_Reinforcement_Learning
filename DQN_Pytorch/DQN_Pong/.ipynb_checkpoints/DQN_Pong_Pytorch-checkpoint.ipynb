{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suresh-venkate/Deep_Reinforcement_Learning/blob/main/DQN_Pytorch/DQN_Pong/.ipynb_checkpoints/DQN_Pong_Pytorch-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icxzwfk7YXbK"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "id": "ujywoe_bZlcF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeqQoIk4YXbS",
        "outputId": "43e1e1b3-3603-44a1-dc7e-b2cc16a9453d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:424: UserWarning: \u001b[33mWARN: Custom namespace `ALE` is being overridden by namespace `ALE`. If you are developing a plugin you shouldn't specify a namespace in `register` calls. The namespace is specified through the entry point package metadata.\u001b[0m\n",
            "  f\"Custom namespace `{spec.namespace}` is being overridden \"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "import cv2\n",
        "import gym\n",
        "from gym import wrappers\n",
        "from IPython import display\n",
        "\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ_cbw0fYXbV"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbTy80cxYXbV"
      },
      "source": [
        "## Class: RepeatActionAndMaxFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z1YkUWv_YXbW"
      },
      "outputs": [],
      "source": [
        "class RepeatActionAndMaxFrame(gym.Wrapper):\n",
        "    def __init__(self, env=None, repeat=4, clip_reward=False, no_ops=0,\n",
        "                 fire_first=False):\n",
        "        \"\"\"\n",
        "        env: Environment to add wrapper around\n",
        "        repeat: Number of times each action is executed \n",
        "        clip_reward: Boolean. If True, clip reward to +/-1 range\n",
        "        no_ops:\n",
        "        fire_first:\n",
        "        \"\"\"\n",
        "        super(RepeatActionAndMaxFrame, self).__init__(env)\n",
        "        self.repeat = repeat\n",
        "        self.shape = env.observation_space.low.shape # Shape of observation from environment\n",
        "        self.frame_buffer = np.zeros_like((2, self.shape)) # Initialize frame_buffer\n",
        "        self.clip_reward = clip_reward\n",
        "        self.no_ops = no_ops\n",
        "        self.fire_first = fire_first\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Executes action self.repeat times and captures total reward in t_reward\n",
        "        Reward is clipped if self.clip_reward is True\n",
        "        \"\"\"\n",
        "        t_reward = 0.0 # Initialize total reward over repeated actions to zero\n",
        "        done = False\n",
        "        for i in range(self.repeat): # Repeat actions 'self.repeat' times\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            if self.clip_reward:\n",
        "                reward = np.clip(np.array([reward]), -1, 1)[0]\n",
        "            t_reward += reward # Increment t_reward with current reward\n",
        "            idx = i % 2\n",
        "            self.frame_buffer[idx] = obs # Frame_buffer updated with last two observations\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        max_frame = np.maximum(self.frame_buffer[0], self.frame_buffer[1]) # Take maximum of last two frames\n",
        "        return max_frame, t_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Wrapper for environment reset\n",
        "        \"\"\"\n",
        "        obs = self.env.reset() # Reset environment\n",
        "        no_ops = np.random.randint(self.no_ops) + 1 if self.no_ops > 0 else 0\n",
        "        for _ in range(no_ops):\n",
        "            _, _, done, _ = self.env.step(0)\n",
        "            if done:\n",
        "                self.env.reset()\n",
        "        if self.fire_first:\n",
        "            assert self.env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "            obs, _, _, _ = self.env.step(1)\n",
        "\n",
        "        self.frame_buffer = np.zeros_like((2,self.shape)) # Initialize frame buffer to zeros\n",
        "        self.frame_buffer[0] = obs # Update frame buffer with first observation after reset\n",
        "\n",
        "        return obs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTLa0_OYXbY"
      },
      "source": [
        "## Class: preprocessFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D9RkTWymYXbZ"
      },
      "outputs": [],
      "source": [
        "class PreprocessFrame(gym.ObservationWrapper):\n",
        "    def __init__(self, shape, env=None):\n",
        "        \"\"\"\n",
        "        Class to pre-process frame.\n",
        "        Frame converted from RGB to grayscale, resized to new shape in C,H,W format\n",
        "        \n",
        "        Arguments:\n",
        "            shape: Shape to pre-process frame to\n",
        "            env: Environment which will be wrapped\n",
        "        \"\"\"\n",
        "        super(PreprocessFrame, self).__init__(env)\n",
        "        self.shape = (shape[2], shape[0], shape[1]) # Change to C,H,W format\n",
        "        # Change observation space to match new shape and dtype to float32 with range = [0.0, 1.0]\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0,shape=self.shape, dtype=np.float32)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        \"\"\"\n",
        "        obs converted from RGB to grayscale and resized to new shape in C,H,W format\n",
        "        \n",
        "        Argument:\n",
        "            obs: Input Frame in color format\n",
        "        Output:\n",
        "            new_obs: Output Frame in grayscale and C,H,W format\n",
        "        \"\"\"\n",
        "        new_frame = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY) # Convert frame to grayscale\n",
        "        resized_screen = cv2.resize(new_frame, self.shape[1:], interpolation=cv2.INTER_AREA) # Resize frame to new shape\n",
        "        new_obs = np.array(resized_screen, dtype=np.uint8).reshape(self.shape)\n",
        "        new_obs = new_obs / 255.0 # Convert to float32 in range [0.0, 1.0]\n",
        "\n",
        "        return new_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUcAsqFmYXbb"
      },
      "source": [
        "## Class: StackFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-ORk3F02YXbc"
      },
      "outputs": [],
      "source": [
        "class StackFrames(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    Class to return stack of last 4 observations\n",
        "    \"\"\"\n",
        "    def __init__(self, env, repeat):\n",
        "        \"\"\"\n",
        "        Arguments: \n",
        "            env: Environment to wrap\n",
        "            repeat: Number of observations to stack\n",
        "        \"\"\"\n",
        "        super(StackFrames, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "                            env.observation_space.low.repeat(repeat, axis=0),\n",
        "                            env.observation_space.high.repeat(repeat, axis=0),\n",
        "                            dtype=np.float32)\n",
        "        self.stack = collections.deque(maxlen=repeat)\n",
        "\n",
        "    def reset(self):\n",
        "        self.stack.clear()\n",
        "        observation = self.env.reset()\n",
        "        for _ in range(self.stack.maxlen):\n",
        "            self.stack.append(observation)\n",
        "\n",
        "        return np.array(self.stack).reshape(self.observation_space.low.shape)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        \"\"\"\n",
        "        Append latest observation to stack\n",
        "        \"\"\"\n",
        "        self.stack.append(observation)\n",
        "\n",
        "        return np.array(self.stack).reshape(self.observation_space.low.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrZqim2sYXbd"
      },
      "source": [
        "## Class: DeepQNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t1oQ_4UlYXbe"
      },
      "outputs": [],
      "source": [
        "class DeepQNetwork(nn.Module):\n",
        "    def __init__(self, lr, n_actions, name, input_dims, chkpt_dir):\n",
        "        super(DeepQNetwork, self).__init__()\n",
        "        self.checkpoint_dir = chkpt_dir\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, name)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(input_dims[0], 32, 8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
        "\n",
        "        fc_input_dims = self.calculate_conv_output_dims(input_dims)\n",
        "\n",
        "        self.fc1 = nn.Linear(fc_input_dims, 512)\n",
        "        self.fc2 = nn.Linear(512, n_actions)\n",
        "\n",
        "        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
        "\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def calculate_conv_output_dims(self, input_dims):\n",
        "        state = T.zeros(1, *input_dims)\n",
        "        dims = self.conv1(state)\n",
        "        dims = self.conv2(dims)\n",
        "        dims = self.conv3(dims)\n",
        "        return int(np.prod(dims.size()))\n",
        "\n",
        "    def forward(self, state):\n",
        "        conv1 = F.relu(self.conv1(state))\n",
        "        conv2 = F.relu(self.conv2(conv1))\n",
        "        conv3 = F.relu(self.conv3(conv2))\n",
        "        # conv3 shape is BS x n_filters x H x W\n",
        "        conv_state = conv3.view(conv3.size()[0], -1)\n",
        "        # conv_state shape is BS x (n_filters * H * W)\n",
        "        flat1 = F.relu(self.fc1(conv_state))\n",
        "        actions = self.fc2(flat1)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        print('... saving checkpoint ...')\n",
        "        T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        print('... loading checkpoint ...')\n",
        "        self.load_state_dict(T.load(self.checkpoint_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYOsO9qWYXbf"
      },
      "source": [
        "## Class: ReplayBuffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F8pwXFN_YXbf"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, max_size, input_shape):\n",
        "        self.mem_size = max_size\n",
        "        self.mem_cntr = 0\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_shape),dtype=np.float32)\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *input_shape),dtype=np.float32)\n",
        "        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
        "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_, done):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        self.state_memory[index] = state\n",
        "        self.new_state_memory[index] = state_\n",
        "        self.action_memory[index] = action\n",
        "        self.reward_memory[index] = reward\n",
        "        self.terminal_memory[index] = done\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
        "        states = self.state_memory[batch]\n",
        "        actions = self.action_memory[batch]\n",
        "        rewards = self.reward_memory[batch]\n",
        "        states_ = self.new_state_memory[batch]\n",
        "        terminal = self.terminal_memory[batch]\n",
        "\n",
        "        return states, actions, rewards, states_, terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VzKsbDuYXbg"
      },
      "source": [
        "## Class: DQNAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OArPrZwvYXbg"
      },
      "outputs": [],
      "source": [
        "class DQNAgent(object):\n",
        "    def __init__(self, gamma, epsilon, lr, n_actions, input_dims,\n",
        "                 mem_size, batch_size, eps_min=0.01, eps_dec=5e-7,\n",
        "                 replace=1000, algo=None, env_name=None, chkpt_dir='tmp/dqn'):\n",
        "        self.gamma = gamma # Discount Factor\n",
        "        self.epsilon = epsilon # for eps-greedy action selection\n",
        "        self.lr = lr # Learning Rate\n",
        "        self.n_actions = n_actions # Number of actions\n",
        "        self.input_dims = input_dims # Dimension of observations from wrapped environment\n",
        "        self.batch_size = batch_size # Batch size to use while training\n",
        "        self.eps_min = eps_min # Minimum eps-value to use while training\n",
        "        self.eps_dec = eps_dec # Decay rate of epsilon\n",
        "        self.replace_target_cnt = replace # Rate at which target network will be replaced\n",
        "        self.algo = algo # Name of learning algorithm\n",
        "        self.env_name = env_name # Name of environment\n",
        "        self.chkpt_dir = chkpt_dir # Directory to save checkpoint files\n",
        "        self.action_space = [i for i in range(n_actions)] # Action space\n",
        "        self.learn_step_counter = 0 # Number of learning steps completed so far\n",
        "\n",
        "        self.memory = ReplayBuffer(mem_size, input_dims) # Instantiate replay buffer object\n",
        "\n",
        "        # Instantiate main DQN\n",
        "        self.q_eval = DeepQNetwork(self.lr, self.n_actions, input_dims=self.input_dims,\\\n",
        "                                   name=self.env_name+'_'+self.algo+'_q_eval', chkpt_dir=self.chkpt_dir)\n",
        "        # Instantiate target DQN\n",
        "        self.q_next = DeepQNetwork(self.lr, self.n_actions, input_dims=self.input_dims,\\\n",
        "                                   name=self.env_name+'_'+self.algo+'_q_next', chkpt_dir=self.chkpt_dir)\n",
        "\n",
        "    def choose_action(self, observation):\n",
        "        \"\"\"\n",
        "        Perform epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        if np.random.random() > self.epsilon: # Choose greedy action with probability '1 - epsilon'\n",
        "            state = T.tensor([observation],dtype=T.float).to(self.q_eval.device)\n",
        "            actions = self.q_eval.forward(state)\n",
        "            action = T.argmax(actions).item()\n",
        "        else: # Choose an action randomly with probability 'epsilon'\n",
        "            action = np.random.choice(self.action_space)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_, done):\n",
        "        \"\"\"\n",
        "        Update replay memory buffer with latest entry\n",
        "        \"\"\"\n",
        "        self.memory.store_transition(state, action, reward, state_, done)\n",
        "\n",
        "    def replace_target_network(self):\n",
        "        \"\"\"\n",
        "        Update target DQN weights with main DQN weights every 'replace_target_cnt' steps\n",
        "        \"\"\"\n",
        "        if self.learn_step_counter % self.replace_target_cnt == 0:\n",
        "            self.q_next.load_state_dict(self.q_eval.state_dict())\n",
        "            \n",
        "    def sample_memory(self):\n",
        "        \"\"\"\n",
        "        Sample a random batch from replay memory\n",
        "        \"\"\"\n",
        "        state, action, reward, new_state, done = self.memory.sample_buffer(self.batch_size)\n",
        "        states = T.tensor(state).to(self.q_eval.device)\n",
        "        rewards = T.tensor(reward).to(self.q_eval.device)\n",
        "        dones = T.tensor(done).to(self.q_eval.device)\n",
        "        actions = T.tensor(action).to(self.q_eval.device)\n",
        "        states_ = T.tensor(new_state).to(self.q_eval.device)\n",
        "\n",
        "        return states, actions, rewards, states_, dones            \n",
        "\n",
        "    def decrement_epsilon(self):\n",
        "        \"\"\"\n",
        "        Decrease epsilon after every learning step and clamp at eps_min\n",
        "        \"\"\"\n",
        "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min\n",
        "\n",
        "    def save_models(self):\n",
        "        \"\"\"\n",
        "        Save checkpoints for both DQN models\n",
        "        \"\"\"\n",
        "        self.q_eval.save_checkpoint()\n",
        "        self.q_next.save_checkpoint()\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"\n",
        "        Load checkpoints for both DQN models\n",
        "        \"\"\"\n",
        "        self.q_eval.load_checkpoint()\n",
        "        self.q_next.load_checkpoint()\n",
        "\n",
        "    def learn(self):\n",
        "        \"\"\"\n",
        "        Perform one learning step\n",
        "        \"\"\"\n",
        "        # Start learning only after replay_memory has atleast 'batch_size' elements\n",
        "        if self.memory.mem_cntr < self.batch_size:\n",
        "            return\n",
        "        self.q_eval.optimizer.zero_grad() # Reset optimizer gradients\n",
        "        self.replace_target_network() # Replace target DQN weights with main DQN weights\n",
        "        states, actions, rewards, states_, dones = self.sample_memory() # Sample a new batch from replay memory\n",
        "        indices = np.arange(self.batch_size)\n",
        "\n",
        "        q_pred = self.q_eval.forward(states)[indices, actions] # Q-values of current states\n",
        "        q_next = self.q_next.forward(states_).max(dim=1)[0] # Q-values of next states\n",
        "        q_next[dones] = 0.0 # Set terminal state q-values to 0.\n",
        "        q_target = rewards + self.gamma*q_next # # Target Q-values for current states\n",
        "\n",
        "        loss = self.q_eval.loss(q_target, q_pred).to(self.q_eval.device) # MSE Loss between current and target Q-values\n",
        "        loss.backward() # Compute gradients\n",
        "        self.q_eval.optimizer.step() # Update weights\n",
        "        \n",
        "        self.learn_step_counter += 1 # Increment learning step counter by 1.\n",
        "        self.decrement_epsilon()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fz89CVIYXbh"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5PRm24sYXbi"
      },
      "source": [
        "## make_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EKln8MK-YXbi"
      },
      "outputs": [],
      "source": [
        "def make_env(env_name, shape=(84,84,1), repeat=4, clip_rewards=False, no_ops=0, fire_first=False):\n",
        "#     env = gym.make(env_name, render_mode = 'human') # Instantiate original environment from gym\n",
        "    env = gym.make(env_name) # Instantiate original environment from gym    \n",
        "    env = RepeatActionAndMaxFrame(env, repeat, clip_rewards, no_ops, fire_first) # Wrapper to repeat action, clip_rewards \n",
        "                                                                                 # and return max of latest two frames\n",
        "    env = PreprocessFrame(shape, env) # Convert observation to grayscale and scale to new dimension in C,H,W format\n",
        "    env = StackFrames(env, repeat) # Stack last n observations\n",
        "\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPzxzWzyYXbj"
      },
      "source": [
        "# Verify Functions and Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZc8D5zKYXbj"
      },
      "source": [
        "## Verify Function: make_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "w94B3P3NYXbk",
        "outputId": "6fa55c42-78c5-4c6d-fed6-859826c81d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 84, 84) 0.0 False {'lives': 0, 'episode_frame_number': 8, 'frame_number': 8}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "env = make_env('PongNoFrameskip-v4')\n",
        "obs = env.reset()\n",
        "\n",
        "s,r,d,i = env.step(0) # Run first step\n",
        "s,r,d,i = env.step(0) # Run second step\n",
        "print(s.shape, r, d, i)\n",
        "fig,ax = plt.subplots(1, 4, figsize = (20, 8))\n",
        "for ind in range(4):\n",
        "    obs_temp = s[ind, :]\n",
        "    ax[ind].imshow(obs_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NagUtNH2YXbl"
      },
      "source": [
        "## Verify Class: DeepQNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRerKnC1YXbl",
        "outputId": "bc48069e-d2b8-4f31-ba16-8ca00dba4217"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepQNetwork(\n",
              "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=6, bias=True)\n",
              "  (loss): MSELoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "temp_model = DeepQNetwork(lr = 0.0001, n_actions = env.action_space.n, input_dims = env.observation_space.shape,\\\n",
        "                          name = '_q_eval', chkpt_dir = 'Models/')\n",
        "temp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sujJz8nwYXbm"
      },
      "source": [
        "## Verify Class: ReplayBuffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF7z-bl0YXbm",
        "outputId": "cf841937-20cb-475d-cf6d-5a7fb1f6e1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "0\n",
            "(10, 1)\n",
            "(10, 1)\n",
            "[0 0 0 0 0 0 0 0 0 0] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [False False False False False False False False False False]\n",
            "\n",
            "7\n",
            "\n",
            "[0.] [3.] 1 2.0 False\n",
            "[1.] [4.] 2 3.0 True\n",
            "[2.] [5.] 3 4.0 False\n",
            "[3.] [6.] 4 5.0 True\n",
            "[4.] [7.] 5 6.0 False\n",
            "[5.] [8.] 6 7.0 True\n",
            "[6.] [9.] 7 8.0 False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ],
      "source": [
        "rp_buff = ReplayBuffer(10, [1])\n",
        "print(rp_buff.mem_size)\n",
        "print(rp_buff.mem_cntr)\n",
        "print(rp_buff.state_memory.shape)\n",
        "print(rp_buff.new_state_memory.shape)\n",
        "print(rp_buff.action_memory, rp_buff.reward_memory, rp_buff.terminal_memory)\n",
        "print()\n",
        "\n",
        "for ind in range(7):\n",
        "    rp_buff.store_transition([ind], ind+1, ind+2, [ind + 3], ind % 2)\n",
        "\n",
        "print(rp_buff.mem_cntr)\n",
        "print()\n",
        "for ind in range(rp_buff.mem_cntr):\n",
        "    print(rp_buff.state_memory[ind], rp_buff.new_state_memory[ind], rp_buff.action_memory[ind],\\\n",
        "         rp_buff.reward_memory[ind], rp_buff.terminal_memory[ind])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FPpHt2cYXbn",
        "outputId": "db418e75-3aed-421b-b1e8-400f61d19b36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [6.]], dtype=float32),\n",
              " array([6, 3, 4, 2, 7]),\n",
              " array([7., 4., 5., 3., 8.], dtype=float32),\n",
              " array([[8.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [4.],\n",
              "        [9.]], dtype=float32),\n",
              " array([ True, False,  True,  True, False]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "rp_buff.sample_buffer(batch_size = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EkEidaLYXbn"
      },
      "source": [
        "# Run training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yEdc6WXlYXbn",
        "outputId": "423262dc-a960-4395-ad84-cc8ffd211537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode:  0 score:  -21.0  average score -21.0 best score -inf epsilon 0.99 steps 783\n",
            "episode:  1 score:  -20.0  average score -20.5 best score -21.00 epsilon 0.98 steps 1650\n",
            "episode:  2 score:  -20.0  average score -20.3 best score -20.50 epsilon 0.97 steps 2674\n",
            "episode:  3 score:  -20.0  average score -20.2 best score -20.33 epsilon 0.96 steps 3624\n",
            "episode:  4 score:  -21.0  average score -20.4 best score -20.25 epsilon 0.96 steps 4435\n",
            "episode:  5 score:  -21.0  average score -20.5 best score -20.25 epsilon 0.95 steps 5228\n",
            "episode:  6 score:  -19.0  average score -20.3 best score -20.25 epsilon 0.93 steps 6540\n",
            "episode:  7 score:  -20.0  average score -20.2 best score -20.25 epsilon 0.93 steps 7472\n",
            "episode:  8 score:  -21.0  average score -20.3 best score -20.25 epsilon 0.92 steps 8385\n",
            "episode:  9 score:  -21.0  average score -20.4 best score -20.25 epsilon 0.91 steps 9418\n",
            "episode:  10 score:  -20.0  average score -20.4 best score -20.25 epsilon 0.90 steps 10317\n",
            "episode:  11 score:  -21.0  average score -20.4 best score -20.25 epsilon 0.89 steps 11342\n",
            "episode:  12 score:  -21.0  average score -20.5 best score -20.25 epsilon 0.88 steps 12169\n",
            "episode:  13 score:  -21.0  average score -20.5 best score -20.25 epsilon 0.87 steps 13121\n",
            "episode:  14 score:  -20.0  average score -20.5 best score -20.25 epsilon 0.86 steps 13991\n",
            "episode:  15 score:  -18.0  average score -20.3 best score -20.25 epsilon 0.85 steps 15160\n",
            "episode:  16 score:  -21.0  average score -20.4 best score -20.25 epsilon 0.84 steps 16120\n",
            "episode:  17 score:  -19.0  average score -20.3 best score -20.25 epsilon 0.83 steps 17139\n",
            "episode:  18 score:  -21.0  average score -20.3 best score -20.25 epsilon 0.82 steps 18057\n",
            "episode:  19 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.81 steps 19020\n",
            "episode:  20 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.80 steps 19862\n",
            "episode:  21 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.79 steps 20871\n",
            "episode:  22 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.78 steps 21882\n",
            "episode:  23 score:  -21.0  average score -20.3 best score -20.25 epsilon 0.77 steps 22873\n",
            "episode:  24 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.76 steps 23925\n",
            "episode:  25 score:  -21.0  average score -20.3 best score -20.25 epsilon 0.75 steps 24951\n",
            "episode:  26 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.74 steps 26079\n",
            "episode:  27 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.73 steps 27219\n",
            "episode:  28 score:  -21.0  average score -20.3 best score -20.25 epsilon 0.72 steps 28150\n",
            "episode:  29 score:  -19.0  average score -20.3 best score -20.25 epsilon 0.71 steps 29419\n",
            "episode:  30 score:  -20.0  average score -20.3 best score -20.25 epsilon 0.70 steps 30319\n",
            "episode:  31 score:  -20.0  average score -20.2 best score -20.25 epsilon 0.69 steps 31499\n",
            "episode:  32 score:  -16.0  average score -20.1 best score -20.25 epsilon 0.67 steps 32939\n",
            "episode:  33 score:  -20.0  average score -20.1 best score -20.12 epsilon 0.66 steps 34271\n",
            "episode:  34 score:  -20.0  average score -20.1 best score -20.12 epsilon 0.65 steps 35502\n",
            "episode:  35 score:  -19.0  average score -20.1 best score -20.11 epsilon 0.63 steps 36818\n",
            "episode:  36 score:  -17.0  average score -20.0 best score -20.08 epsilon 0.62 steps 38291\n",
            "episode:  37 score:  -19.0  average score -20.0 best score -20.00 epsilon 0.60 steps 39865\n",
            "episode:  38 score:  -18.0  average score -19.9 best score -19.97 epsilon 0.59 steps 41264\n",
            "episode:  39 score:  -18.0  average score -19.9 best score -19.92 epsilon 0.57 steps 42801\n",
            "episode:  40 score:  -19.0  average score -19.9 best score -19.88 epsilon 0.56 steps 43887\n",
            "episode:  41 score:  -18.0  average score -19.8 best score -19.85 epsilon 0.55 steps 45482\n",
            "episode:  42 score:  -15.0  average score -19.7 best score -19.81 epsilon 0.53 steps 47164\n",
            "episode:  43 score:  -21.0  average score -19.7 best score -19.70 epsilon 0.52 steps 48233\n",
            "episode:  44 score:  -18.0  average score -19.7 best score -19.70 epsilon 0.50 steps 49761\n",
            "episode:  45 score:  -14.0  average score -19.6 best score -19.69 epsilon 0.48 steps 51697\n",
            "episode:  46 score:  -19.0  average score -19.6 best score -19.57 epsilon 0.47 steps 52924\n",
            "episode:  47 score:  -18.0  average score -19.5 best score -19.55 epsilon 0.46 steps 54443\n",
            "episode:  48 score:  -17.0  average score -19.5 best score -19.52 epsilon 0.44 steps 56068\n",
            "episode:  49 score:  -16.0  average score -19.4 best score -19.47 epsilon 0.42 steps 58454\n",
            "episode:  50 score:  -12.0  average score -19.3 best score -19.40 epsilon 0.39 steps 60532\n",
            "episode:  51 score:  -17.0  average score -19.2 best score -19.25 epsilon 0.38 steps 62455\n",
            "episode:  52 score:  -18.0  average score -19.2 best score -19.21 epsilon 0.36 steps 64196\n",
            "episode:  53 score:  -17.0  average score -19.1 best score -19.19 epsilon 0.34 steps 66280\n",
            "episode:  54 score:  -19.0  average score -19.1 best score -19.15 epsilon 0.32 steps 68024\n",
            "episode:  55 score:  -11.0  average score -19.0 best score -19.15 epsilon 0.30 steps 70520\n",
            "episode:  56 score:  -18.0  average score -19.0 best score -19.00 epsilon 0.27 steps 72569\n",
            "episode:  57 score:  -17.0  average score -18.9 best score -18.98 epsilon 0.25 steps 74721\n",
            "episode:  58 score:  -9.0  average score -18.8 best score -18.95 epsilon 0.23 steps 77372\n",
            "episode:  59 score:  -17.0  average score -18.8 best score -18.78 epsilon 0.21 steps 79120\n",
            "episode:  60 score:  -16.0  average score -18.7 best score -18.75 epsilon 0.18 steps 81737\n",
            "episode:  61 score:  -19.0  average score -18.7 best score -18.70 epsilon 0.17 steps 83367\n",
            "episode:  62 score:  -15.0  average score -18.7 best score -18.70 epsilon 0.14 steps 85708\n",
            "episode:  63 score:  -14.0  average score -18.6 best score -18.65 epsilon 0.12 steps 88444\n",
            "episode:  64 score:  -16.0  average score -18.5 best score -18.58 epsilon 0.10 steps 90475\n",
            "episode:  65 score:  -11.0  average score -18.4 best score -18.54 epsilon 0.10 steps 92961\n",
            "episode:  66 score:  -13.0  average score -18.3 best score -18.42 epsilon 0.10 steps 95755\n",
            "episode:  67 score:  -14.0  average score -18.3 best score -18.34 epsilon 0.10 steps 98262\n",
            "episode:  68 score:  -16.0  average score -18.2 best score -18.28 epsilon 0.10 steps 100009\n",
            "episode:  69 score:  -17.0  average score -18.2 best score -18.25 epsilon 0.10 steps 102098\n",
            "episode:  70 score:  -12.0  average score -18.1 best score -18.23 epsilon 0.10 steps 104888\n",
            "episode:  71 score:  -14.0  average score -18.1 best score -18.14 epsilon 0.10 steps 107892\n",
            "episode:  72 score:  -17.0  average score -18.1 best score -18.08 epsilon 0.10 steps 110090\n",
            "episode:  73 score:  -15.0  average score -18.0 best score -18.07 epsilon 0.10 steps 112437\n",
            "episode:  74 score:  -15.0  average score -18.0 best score -18.03 epsilon 0.10 steps 114610\n",
            "episode:  75 score:  -14.0  average score -17.9 best score -17.99 epsilon 0.10 steps 117352\n",
            "episode:  76 score:  -15.0  average score -17.9 best score -17.93 epsilon 0.10 steps 119799\n",
            "episode:  77 score:  -14.0  average score -17.8 best score -17.90 epsilon 0.10 steps 122011\n",
            "episode:  78 score:  -10.0  average score -17.7 best score -17.85 epsilon 0.10 steps 125009\n",
            "episode:  79 score:  -14.0  average score -17.7 best score -17.75 epsilon 0.10 steps 126799\n",
            "episode:  80 score:  -13.0  average score -17.6 best score -17.70 epsilon 0.10 steps 128913\n",
            "episode:  81 score:  -12.0  average score -17.6 best score -17.64 epsilon 0.10 steps 131393\n",
            "episode:  82 score:  -9.0  average score -17.5 best score -17.57 epsilon 0.10 steps 133942\n",
            "episode:  83 score:  -7.0  average score -17.3 best score -17.47 epsilon 0.10 steps 136622\n",
            "episode:  84 score:  -11.0  average score -17.3 best score -17.35 epsilon 0.10 steps 138682\n",
            "episode:  85 score:  2.0  average score -17.0 best score -17.27 epsilon 0.10 steps 142238\n",
            "episode:  86 score:  -8.0  average score -16.9 best score -17.05 epsilon 0.10 steps 145223\n",
            "episode:  87 score:  -5.0  average score -16.8 best score -16.94 epsilon 0.10 steps 148588\n",
            "episode:  88 score:  -6.0  average score -16.7 best score -16.81 epsilon 0.10 steps 151751\n",
            "episode:  89 score:  -4.0  average score -16.5 best score -16.69 epsilon 0.10 steps 155030\n",
            "episode:  90 score:  2.0  average score -16.3 best score -16.54 epsilon 0.10 steps 158600\n",
            "episode:  91 score:  -3.0  average score -16.2 best score -16.34 epsilon 0.10 steps 161704\n",
            "episode:  92 score:  -6.0  average score -16.1 best score -16.20 epsilon 0.10 steps 164434\n",
            "episode:  93 score:  -1.0  average score -15.9 best score -16.09 epsilon 0.10 steps 167585\n",
            "episode:  94 score:  7.0  average score -15.7 best score -15.93 epsilon 0.10 steps 170368\n",
            "episode:  95 score:  1.0  average score -15.5 best score -15.68 epsilon 0.10 steps 173528\n",
            "episode:  96 score:  3.0  average score -15.3 best score -15.51 epsilon 0.10 steps 176513\n",
            "episode:  97 score:  11.0  average score -15.1 best score -15.32 epsilon 0.10 steps 178965\n",
            "episode:  98 score:  12.0  average score -14.8 best score -15.05 epsilon 0.10 steps 181340\n",
            "episode:  99 score:  2.0  average score -14.6 best score -14.78 epsilon 0.10 steps 184447\n",
            "episode:  100 score:  10.0  average score -14.3 best score -14.61 epsilon 0.10 steps 187082\n",
            "episode:  101 score:  5.0  average score -14.1 best score -14.30 epsilon 0.10 steps 189933\n",
            "episode:  102 score:  15.0  average score -13.7 best score -14.05 epsilon 0.10 steps 192017\n",
            "episode:  103 score:  15.0  average score -13.3 best score -13.70 epsilon 0.10 steps 194328\n",
            "episode:  104 score:  5.0  average score -13.1 best score -13.35 epsilon 0.10 steps 197486\n",
            "episode:  105 score:  14.0  average score -12.7 best score -13.09 epsilon 0.10 steps 199578\n",
            "episode:  106 score:  8.0  average score -12.5 best score -12.74 epsilon 0.10 steps 202304\n",
            "episode:  107 score:  14.0  average score -12.1 best score -12.47 epsilon 0.10 steps 204898\n",
            "episode:  108 score:  -2.0  average score -11.9 best score -12.13 epsilon 0.10 steps 208319\n",
            "episode:  109 score:  14.0  average score -11.6 best score -11.94 epsilon 0.10 steps 210604\n",
            "episode:  110 score:  -1.0  average score -11.4 best score -11.59 epsilon 0.10 steps 213740\n",
            "episode:  111 score:  8.0  average score -11.1 best score -11.40 epsilon 0.10 steps 216221\n",
            "episode:  112 score:  7.0  average score -10.8 best score -11.11 epsilon 0.10 steps 218840\n",
            "episode:  113 score:  8.0  average score -10.5 best score -10.83 epsilon 0.10 steps 221390\n",
            "episode:  114 score:  -1.0  average score -10.3 best score -10.54 epsilon 0.10 steps 224467\n",
            "episode:  115 score:  6.0  average score -10.1 best score -10.35 epsilon 0.10 steps 227046\n",
            "episode:  116 score:  10.0  average score -9.8 best score -10.11 epsilon 0.10 steps 229552\n",
            "episode:  117 score:  18.0  average score -9.4 best score -9.80 epsilon 0.10 steps 231442\n",
            "episode:  118 score:  11.0  average score -9.1 best score -9.43 epsilon 0.10 steps 234034\n",
            "episode:  119 score:  13.0  average score -8.8 best score -9.11 epsilon 0.10 steps 236428\n",
            "episode:  120 score:  8.0  average score -8.5 best score -8.78 epsilon 0.10 steps 239057\n",
            "episode:  121 score:  6.0  average score -8.2 best score -8.50 epsilon 0.10 steps 242051\n",
            "episode:  122 score:  2.0  average score -8.0 best score -8.24 epsilon 0.10 steps 244820\n",
            "episode:  123 score:  17.0  average score -7.6 best score -8.02 epsilon 0.10 steps 247173\n",
            "episode:  124 score:  7.0  average score -7.4 best score -7.64 epsilon 0.10 steps 249807\n",
            "episode:  125 score:  17.0  average score -7.0 best score -7.37 epsilon 0.10 steps 251818\n",
            "episode:  126 score:  7.0  average score -6.7 best score -6.99 epsilon 0.10 steps 254858\n",
            "episode:  127 score:  9.0  average score -6.4 best score -6.72 epsilon 0.10 steps 257457\n",
            "episode:  128 score:  12.0  average score -6.1 best score -6.43 epsilon 0.10 steps 259812\n",
            "episode:  129 score:  12.0  average score -5.8 best score -6.10 epsilon 0.10 steps 262124\n",
            "episode:  130 score:  19.0  average score -5.4 best score -5.79 epsilon 0.10 steps 263852\n",
            "episode:  131 score:  14.0  average score -5.1 best score -5.40 epsilon 0.10 steps 266003\n",
            "episode:  132 score:  8.0  average score -4.8 best score -5.06 epsilon 0.10 steps 268930\n",
            "episode:  133 score:  5.0  average score -4.6 best score -4.82 epsilon 0.10 steps 272190\n",
            "episode:  134 score:  8.0  average score -4.3 best score -4.57 epsilon 0.10 steps 275049\n",
            "episode:  135 score:  12.0  average score -4.0 best score -4.29 epsilon 0.10 steps 277457\n",
            "episode:  136 score:  4.0  average score -3.8 best score -3.98 epsilon 0.10 steps 280583\n",
            "episode:  137 score:  10.0  average score -3.5 best score -3.77 epsilon 0.10 steps 283193\n",
            "episode:  138 score:  14.0  average score -3.2 best score -3.48 epsilon 0.10 steps 285246\n",
            "episode:  139 score:  5.0  average score -2.9 best score -3.16 epsilon 0.10 steps 288472\n",
            "episode:  140 score:  12.0  average score -2.6 best score -2.93 epsilon 0.10 steps 291093\n",
            "episode:  141 score:  12.0  average score -2.3 best score -2.62 epsilon 0.10 steps 293392\n",
            "episode:  142 score:  7.0  average score -2.1 best score -2.32 epsilon 0.10 steps 295998\n",
            "episode:  143 score:  9.0  average score -1.8 best score -2.10 epsilon 0.10 steps 298792\n",
            "episode:  144 score:  7.0  average score -1.6 best score -1.80 epsilon 0.10 steps 301560\n",
            "episode:  145 score:  6.0  average score -1.4 best score -1.55 epsilon 0.10 steps 304524\n",
            "episode:  146 score:  11.0  average score -1.1 best score -1.35 epsilon 0.10 steps 306961\n",
            "episode:  147 score:  10.0  average score -0.8 best score -1.05 epsilon 0.10 steps 309399\n",
            "episode:  148 score:  9.0  average score -0.5 best score -0.77 epsilon 0.10 steps 311815\n",
            "episode:  149 score:  12.0  average score -0.2 best score -0.51 epsilon 0.10 steps 314262\n",
            "episode:  150 score:  16.0  average score 0.1 best score -0.23 epsilon 0.10 steps 316542\n",
            "episode:  151 score:  12.0  average score 0.3 best score 0.05 epsilon 0.10 steps 319057\n",
            "episode:  152 score:  6.0  average score 0.6 best score 0.34 epsilon 0.10 steps 322002\n",
            "episode:  153 score:  12.0  average score 0.9 best score 0.58 epsilon 0.10 steps 324357\n",
            "episode:  154 score:  12.0  average score 1.2 best score 0.87 epsilon 0.10 steps 326838\n",
            "episode:  155 score:  14.0  average score 1.4 best score 1.18 epsilon 0.10 steps 329134\n",
            "episode:  156 score:  5.0  average score 1.7 best score 1.43 epsilon 0.10 steps 331900\n",
            "episode:  157 score:  17.0  average score 2.0 best score 1.66 epsilon 0.10 steps 334010\n",
            "episode:  158 score:  14.0  average score 2.2 best score 2.00 epsilon 0.10 steps 336234\n",
            "episode:  159 score:  13.0  average score 2.5 best score 2.23 epsilon 0.10 steps 338668\n",
            "episode:  160 score:  6.0  average score 2.8 best score 2.53 epsilon 0.10 steps 341456\n",
            "episode:  161 score:  13.0  average score 3.1 best score 2.75 epsilon 0.10 steps 343593\n",
            "episode:  162 score:  5.0  average score 3.3 best score 3.07 epsilon 0.10 steps 346183\n",
            "episode:  163 score:  9.0  average score 3.5 best score 3.27 epsilon 0.10 steps 348648\n",
            "episode:  164 score:  -4.0  average score 3.6 best score 3.50 epsilon 0.10 steps 350994\n",
            "episode:  165 score:  16.0  average score 3.9 best score 3.62 epsilon 0.10 steps 353192\n",
            "episode:  166 score:  7.0  average score 4.1 best score 3.89 epsilon 0.10 steps 355992\n",
            "episode:  167 score:  10.0  average score 4.3 best score 4.09 epsilon 0.10 steps 358608\n",
            "episode:  168 score:  17.0  average score 4.7 best score 4.33 epsilon 0.10 steps 360704\n",
            "episode:  169 score:  6.0  average score 4.9 best score 4.66 epsilon 0.10 steps 363572\n",
            "episode:  170 score:  17.0  average score 5.2 best score 4.89 epsilon 0.10 steps 365457\n",
            "episode:  171 score:  13.0  average score 5.5 best score 5.18 epsilon 0.10 steps 367626\n",
            "episode:  172 score:  11.0  average score 5.7 best score 5.45 epsilon 0.10 steps 370062\n",
            "episode:  173 score:  16.0  average score 6.0 best score 5.73 epsilon 0.10 steps 372287\n",
            "episode:  174 score:  11.0  average score 6.3 best score 6.04 epsilon 0.10 steps 374793\n",
            "episode:  175 score:  7.0  average score 6.5 best score 6.30 epsilon 0.10 steps 377561\n",
            "episode:  176 score:  12.0  average score 6.8 best score 6.51 epsilon 0.10 steps 379836\n",
            "episode:  177 score:  15.0  average score 7.1 best score 6.78 epsilon 0.10 steps 382192\n",
            "episode:  178 score:  13.0  average score 7.3 best score 7.07 epsilon 0.10 steps 384563\n",
            "episode:  179 score:  11.0  average score 7.5 best score 7.30 epsilon 0.10 steps 387343\n",
            "episode:  180 score:  7.0  average score 7.8 best score 7.55 epsilon 0.10 steps 389989\n",
            "episode:  181 score:  9.0  average score 8.0 best score 7.75 epsilon 0.10 steps 392803\n",
            "episode:  182 score:  9.0  average score 8.1 best score 7.96 epsilon 0.10 steps 395419\n",
            "episode:  183 score:  20.0  average score 8.4 best score 8.14 epsilon 0.10 steps 397318\n",
            "episode:  184 score:  16.0  average score 8.7 best score 8.41 epsilon 0.10 steps 399381\n",
            "episode:  185 score:  15.0  average score 8.8 best score 8.68 epsilon 0.10 steps 401409\n",
            "episode:  186 score:  14.0  average score 9.0 best score 8.81 epsilon 0.10 steps 403495\n",
            "episode:  187 score:  13.0  average score 9.2 best score 9.03 epsilon 0.10 steps 405790\n",
            "episode:  188 score:  13.0  average score 9.4 best score 9.21 epsilon 0.10 steps 408185\n",
            "episode:  189 score:  8.0  average score 9.5 best score 9.40 epsilon 0.10 steps 411206\n",
            "episode:  190 score:  2.0  average score 9.5 best score 9.52 epsilon 0.10 steps 414341\n",
            "episode:  191 score:  17.0  average score 9.7 best score 9.52 epsilon 0.10 steps 416274\n",
            "episode:  192 score:  20.0  average score 10.0 best score 9.72 epsilon 0.10 steps 417966\n",
            "episode:  193 score:  5.0  average score 10.0 best score 9.98 epsilon 0.10 steps 420861\n",
            "episode:  194 score:  11.0  average score 10.1 best score 10.04 epsilon 0.10 steps 423225\n",
            "episode:  195 score:  -6.0  average score 10.0 best score 10.08 epsilon 0.10 steps 425862\n",
            "episode:  196 score:  14.0  average score 10.1 best score 10.08 epsilon 0.10 steps 427928\n",
            "episode:  197 score:  14.0  average score 10.2 best score 10.12 epsilon 0.10 steps 430067\n",
            "episode:  198 score:  11.0  average score 10.1 best score 10.15 epsilon 0.10 steps 432836\n",
            "episode:  199 score:  12.0  average score 10.2 best score 10.15 epsilon 0.10 steps 435532\n",
            "episode:  200 score:  13.0  average score 10.3 best score 10.24 epsilon 0.10 steps 437926\n",
            "episode:  201 score:  8.0  average score 10.3 best score 10.27 epsilon 0.10 steps 440737\n",
            "episode:  202 score:  16.0  average score 10.3 best score 10.30 epsilon 0.10 steps 442690\n",
            "episode:  203 score:  16.0  average score 10.3 best score 10.31 epsilon 0.10 steps 444721\n",
            "episode:  204 score:  19.0  average score 10.5 best score 10.32 epsilon 0.10 steps 446622\n",
            "episode:  205 score:  11.0  average score 10.4 best score 10.46 epsilon 0.10 steps 449148\n",
            "episode:  206 score:  10.0  average score 10.4 best score 10.46 epsilon 0.10 steps 451893\n",
            "episode:  207 score:  4.0  average score 10.3 best score 10.46 epsilon 0.10 steps 455139\n",
            "episode:  208 score:  11.0  average score 10.5 best score 10.46 epsilon 0.10 steps 457867\n",
            "episode:  209 score:  17.0  average score 10.5 best score 10.48 epsilon 0.10 steps 459943\n",
            "episode:  210 score:  15.0  average score 10.7 best score 10.51 epsilon 0.10 steps 461984\n",
            "episode:  211 score:  11.0  average score 10.7 best score 10.67 epsilon 0.10 steps 464407\n",
            "episode:  212 score:  8.0  average score 10.7 best score 10.70 epsilon 0.10 steps 467021\n",
            "episode:  213 score:  4.0  average score 10.7 best score 10.71 epsilon 0.10 steps 470150\n",
            "episode:  214 score:  13.0  average score 10.8 best score 10.71 epsilon 0.10 steps 472281\n",
            "episode:  215 score:  19.0  average score 10.9 best score 10.81 epsilon 0.10 steps 474207\n",
            "episode:  216 score:  9.0  average score 10.9 best score 10.94 epsilon 0.10 steps 476425\n",
            "episode:  217 score:  2.0  average score 10.8 best score 10.94 epsilon 0.10 steps 479375\n",
            "episode:  218 score:  11.0  average score 10.8 best score 10.94 epsilon 0.10 steps 482287\n",
            "episode:  219 score:  14.0  average score 10.8 best score 10.94 epsilon 0.10 steps 484803\n",
            "episode:  220 score:  6.0  average score 10.8 best score 10.94 epsilon 0.10 steps 487669\n",
            "episode:  221 score:  17.0  average score 10.9 best score 10.94 epsilon 0.10 steps 489594\n",
            "episode:  222 score:  13.0  average score 11.0 best score 10.94 epsilon 0.10 steps 491892\n",
            "episode:  223 score:  13.0  average score 10.9 best score 10.98 epsilon 0.10 steps 494016\n",
            "episode:  224 score:  16.0  average score 11.0 best score 10.98 epsilon 0.10 steps 496118\n",
            "episode:  225 score:  18.0  average score 11.0 best score 11.03 epsilon 0.10 steps 498046\n",
            "episode:  226 score:  13.0  average score 11.1 best score 11.04 epsilon 0.10 steps 500458\n",
            "episode:  227 score:  10.0  average score 11.1 best score 11.10 epsilon 0.10 steps 503102\n",
            "episode:  228 score:  12.0  average score 11.1 best score 11.11 epsilon 0.10 steps 505504\n",
            "episode:  229 score:  14.0  average score 11.1 best score 11.11 epsilon 0.10 steps 508095\n",
            "episode:  230 score:  16.0  average score 11.1 best score 11.13 epsilon 0.10 steps 510207\n",
            "episode:  231 score:  19.0  average score 11.2 best score 11.13 epsilon 0.10 steps 512011\n",
            "episode:  232 score:  16.0  average score 11.2 best score 11.15 epsilon 0.10 steps 514204\n",
            "episode:  233 score:  18.0  average score 11.4 best score 11.23 epsilon 0.10 steps 516110\n",
            "episode:  234 score:  15.0  average score 11.4 best score 11.36 epsilon 0.10 steps 518223\n",
            "episode:  235 score:  10.0  average score 11.4 best score 11.43 epsilon 0.10 steps 520727\n",
            "episode:  236 score:  16.0  average score 11.5 best score 11.43 epsilon 0.10 steps 522685\n",
            "episode:  237 score:  13.0  average score 11.6 best score 11.53 epsilon 0.10 steps 524806\n",
            "episode:  238 score:  16.0  average score 11.6 best score 11.56 epsilon 0.10 steps 527224\n",
            "episode:  239 score:  12.0  average score 11.7 best score 11.58 epsilon 0.10 steps 529556\n",
            "episode:  240 score:  13.0  average score 11.7 best score 11.65 epsilon 0.10 steps 531787\n",
            "episode:  241 score:  11.0  average score 11.7 best score 11.66 epsilon 0.10 steps 534358\n",
            "episode:  242 score:  10.0  average score 11.7 best score 11.66 epsilon 0.10 steps 536832\n",
            "episode:  243 score:  8.0  average score 11.7 best score 11.68 epsilon 0.10 steps 539423\n",
            "episode:  244 score:  16.0  average score 11.8 best score 11.68 epsilon 0.10 steps 541549\n",
            "episode:  245 score:  12.0  average score 11.8 best score 11.76 epsilon 0.10 steps 543807\n",
            "episode:  246 score:  17.0  average score 11.9 best score 11.82 epsilon 0.10 steps 545831\n",
            "episode:  247 score:  17.0  average score 11.9 best score 11.88 epsilon 0.10 steps 547812\n",
            "episode:  248 score:  15.0  average score 12.0 best score 11.95 epsilon 0.10 steps 550086\n",
            "episode:  249 score:  16.0  average score 12.1 best score 12.01 epsilon 0.10 steps 552150\n",
            "episode:  250 score:  17.0  average score 12.1 best score 12.05 epsilon 0.10 steps 554181\n",
            "episode:  251 score:  13.0  average score 12.1 best score 12.06 epsilon 0.10 steps 556453\n",
            "episode:  252 score:  14.0  average score 12.2 best score 12.07 epsilon 0.10 steps 559071\n",
            "episode:  253 score:  19.0  average score 12.2 best score 12.15 epsilon 0.10 steps 561172\n",
            "episode:  254 score:  14.0  average score 12.2 best score 12.22 epsilon 0.10 steps 563477\n",
            "episode:  255 score:  14.0  average score 12.2 best score 12.24 epsilon 0.10 steps 565749\n",
            "episode:  256 score:  12.0  average score 12.3 best score 12.24 epsilon 0.10 steps 568205\n",
            "episode:  257 score:  14.0  average score 12.3 best score 12.31 epsilon 0.10 steps 570592\n",
            "episode:  258 score:  12.0  average score 12.3 best score 12.31 epsilon 0.10 steps 572883\n",
            "episode:  259 score:  16.0  average score 12.3 best score 12.31 epsilon 0.10 steps 574872\n",
            "episode:  260 score:  13.0  average score 12.4 best score 12.31 epsilon 0.10 steps 577037\n",
            "episode:  261 score:  15.0  average score 12.4 best score 12.36 epsilon 0.10 steps 579155\n",
            "episode:  262 score:  12.0  average score 12.4 best score 12.38 epsilon 0.10 steps 581443\n",
            "episode:  263 score:  18.0  average score 12.5 best score 12.45 epsilon 0.10 steps 583460\n",
            "episode:  264 score:  17.0  average score 12.8 best score 12.54 epsilon 0.10 steps 585433\n",
            "episode:  265 score:  15.0  average score 12.7 best score 12.75 epsilon 0.10 steps 587439\n",
            "episode:  266 score:  15.0  average score 12.8 best score 12.75 epsilon 0.10 steps 589591\n",
            "episode:  267 score:  12.0  average score 12.8 best score 12.82 epsilon 0.10 steps 591854\n",
            "episode:  268 score:  15.0  average score 12.8 best score 12.84 epsilon 0.10 steps 594137\n",
            "episode:  269 score:  15.0  average score 12.9 best score 12.84 epsilon 0.10 steps 596223\n",
            "episode:  270 score:  15.0  average score 12.9 best score 12.91 epsilon 0.10 steps 598393\n",
            "episode:  271 score:  17.0  average score 12.9 best score 12.91 epsilon 0.10 steps 600421\n",
            "episode:  272 score:  13.0  average score 12.9 best score 12.93 epsilon 0.10 steps 602923\n",
            "episode:  273 score:  20.0  average score 13.0 best score 12.95 epsilon 0.10 steps 604782\n",
            "episode:  274 score:  19.0  average score 13.1 best score 12.99 epsilon 0.10 steps 606568\n",
            "episode:  275 score:  13.0  average score 13.1 best score 13.07 epsilon 0.10 steps 609002\n",
            "episode:  276 score:  12.0  average score 13.1 best score 13.13 epsilon 0.10 steps 611306\n",
            "episode:  277 score:  15.0  average score 13.1 best score 13.13 epsilon 0.10 steps 613706\n",
            "episode:  278 score:  19.0  average score 13.2 best score 13.13 epsilon 0.10 steps 615467\n",
            "episode:  279 score:  15.0  average score 13.2 best score 13.19 epsilon 0.10 steps 617413\n",
            "episode:  280 score:  13.0  average score 13.3 best score 13.23 epsilon 0.10 steps 619921\n",
            "episode:  281 score:  17.0  average score 13.4 best score 13.29 epsilon 0.10 steps 621815\n",
            "episode:  282 score:  14.0  average score 13.4 best score 13.37 epsilon 0.10 steps 623979\n",
            "episode:  283 score:  11.0  average score 13.3 best score 13.42 epsilon 0.10 steps 626459\n",
            "episode:  284 score:  17.0  average score 13.3 best score 13.42 epsilon 0.10 steps 628349\n",
            "episode:  285 score:  16.0  average score 13.3 best score 13.42 epsilon 0.10 steps 630518\n",
            "episode:  286 score:  19.0  average score 13.4 best score 13.42 epsilon 0.10 steps 632388\n",
            "episode:  287 score:  19.0  average score 13.5 best score 13.42 epsilon 0.10 steps 634444\n",
            "episode:  288 score:  16.0  average score 13.5 best score 13.46 epsilon 0.10 steps 636425\n",
            "episode:  289 score:  17.0  average score 13.6 best score 13.49 epsilon 0.10 steps 638362\n",
            "episode:  290 score:  17.0  average score 13.7 best score 13.58 epsilon 0.10 steps 640358\n",
            "episode:  291 score:  20.0  average score 13.8 best score 13.73 epsilon 0.10 steps 642185\n",
            "episode:  292 score:  11.0  average score 13.7 best score 13.76 epsilon 0.10 steps 644777\n",
            "episode:  293 score:  14.0  average score 13.8 best score 13.76 epsilon 0.10 steps 646932\n",
            "episode:  294 score:  12.0  average score 13.8 best score 13.76 epsilon 0.10 steps 649195\n",
            "episode:  295 score:  16.0  average score 14.0 best score 13.77 epsilon 0.10 steps 651337\n",
            "episode:  296 score:  16.0  average score 14.0 best score 13.99 epsilon 0.10 steps 653442\n",
            "episode:  297 score:  14.0  average score 14.0 best score 14.01 epsilon 0.10 steps 655804\n",
            "episode:  298 score:  19.0  average score 14.1 best score 14.01 epsilon 0.10 steps 657719\n",
            "episode:  299 score:  21.0  average score 14.2 best score 14.09 epsilon 0.10 steps 659415\n",
            "episode:  300 score:  14.0  average score 14.2 best score 14.18 epsilon 0.10 steps 661954\n",
            "episode:  301 score:  12.0  average score 14.2 best score 14.19 epsilon 0.10 steps 664192\n",
            "episode:  302 score:  14.0  average score 14.2 best score 14.23 epsilon 0.10 steps 666518\n",
            "episode:  303 score:  16.0  average score 14.2 best score 14.23 epsilon 0.10 steps 668536\n",
            "episode:  304 score:  17.0  average score 14.2 best score 14.23 epsilon 0.10 steps 670612\n",
            "episode:  305 score:  14.0  average score 14.2 best score 14.23 epsilon 0.10 steps 672934\n",
            "episode:  306 score:  5.0  average score 14.2 best score 14.23 epsilon 0.10 steps 675885\n",
            "episode:  307 score:  18.0  average score 14.3 best score 14.23 epsilon 0.10 steps 677724\n",
            "episode:  308 score:  14.0  average score 14.3 best score 14.31 epsilon 0.10 steps 680088\n",
            "episode:  309 score:  7.0  average score 14.2 best score 14.34 epsilon 0.10 steps 682808\n",
            "episode:  310 score:  17.0  average score 14.3 best score 14.34 epsilon 0.10 steps 684910\n",
            "episode:  311 score:  10.0  average score 14.2 best score 14.34 epsilon 0.10 steps 687624\n",
            "episode:  312 score:  14.0  average score 14.3 best score 14.34 epsilon 0.10 steps 689876\n",
            "episode:  313 score:  17.0  average score 14.4 best score 14.34 epsilon 0.10 steps 691895\n",
            "episode:  314 score:  13.0  average score 14.4 best score 14.44 epsilon 0.10 steps 694125\n",
            "episode:  315 score:  16.0  average score 14.4 best score 14.44 epsilon 0.10 steps 696079\n",
            "episode:  316 score:  15.0  average score 14.5 best score 14.44 epsilon 0.10 steps 698177\n",
            "episode:  317 score:  10.0  average score 14.6 best score 14.47 epsilon 0.10 steps 700821\n",
            "episode:  318 score:  10.0  average score 14.5 best score 14.55 epsilon 0.10 steps 703230\n",
            "episode:  319 score:  16.0  average score 14.6 best score 14.55 epsilon 0.10 steps 705325\n",
            "episode:  320 score:  14.0  average score 14.6 best score 14.56 epsilon 0.10 steps 707485\n",
            "episode:  321 score:  18.0  average score 14.7 best score 14.64 epsilon 0.10 steps 709515\n",
            "episode:  322 score:  14.0  average score 14.7 best score 14.65 epsilon 0.10 steps 711759\n",
            "episode:  323 score:  13.0  average score 14.7 best score 14.66 epsilon 0.10 steps 714335\n",
            "episode:  324 score:  16.0  average score 14.7 best score 14.66 epsilon 0.10 steps 716581\n",
            "episode:  325 score:  15.0  average score 14.6 best score 14.66 epsilon 0.10 steps 718790\n",
            "episode:  326 score:  20.0  average score 14.7 best score 14.66 epsilon 0.10 steps 720533\n",
            "episode:  327 score:  13.0  average score 14.7 best score 14.70 epsilon 0.10 steps 722889\n",
            "episode:  328 score:  13.0  average score 14.7 best score 14.73 epsilon 0.10 steps 725270\n",
            "episode:  329 score:  12.0  average score 14.7 best score 14.74 epsilon 0.10 steps 727556\n",
            "episode:  330 score:  9.0  average score 14.7 best score 14.74 epsilon 0.10 steps 730460\n",
            "episode:  331 score:  13.0  average score 14.6 best score 14.74 epsilon 0.10 steps 732810\n",
            "episode:  332 score:  17.0  average score 14.6 best score 14.74 epsilon 0.10 steps 734888\n",
            "episode:  333 score:  16.0  average score 14.6 best score 14.74 epsilon 0.10 steps 736899\n",
            "episode:  334 score:  7.0  average score 14.5 best score 14.74 epsilon 0.10 steps 739829\n",
            "episode:  335 score:  19.0  average score 14.6 best score 14.74 epsilon 0.10 steps 741722\n",
            "episode:  336 score:  13.0  average score 14.6 best score 14.74 epsilon 0.10 steps 744276\n",
            "episode:  337 score:  15.0  average score 14.6 best score 14.74 epsilon 0.10 steps 746393\n",
            "episode:  338 score:  12.0  average score 14.5 best score 14.74 epsilon 0.10 steps 748765\n",
            "episode:  339 score:  14.0  average score 14.6 best score 14.74 epsilon 0.10 steps 750987\n",
            "episode:  340 score:  14.0  average score 14.6 best score 14.74 epsilon 0.10 steps 753273\n",
            "episode:  341 score:  15.0  average score 14.6 best score 14.74 epsilon 0.10 steps 755498\n",
            "episode:  342 score:  18.0  average score 14.7 best score 14.74 epsilon 0.10 steps 757540\n",
            "episode:  343 score:  16.0  average score 14.8 best score 14.74 epsilon 0.10 steps 759706\n",
            "episode:  344 score:  13.0  average score 14.7 best score 14.77 epsilon 0.10 steps 762127\n",
            "episode:  345 score:  10.0  average score 14.7 best score 14.77 epsilon 0.10 steps 764474\n",
            "episode:  346 score:  11.0  average score 14.7 best score 14.77 epsilon 0.10 steps 767020\n",
            "episode:  347 score:  14.0  average score 14.6 best score 14.77 epsilon 0.10 steps 769451\n",
            "episode:  348 score:  15.0  average score 14.6 best score 14.77 epsilon 0.10 steps 771881\n",
            "episode:  349 score:  11.0  average score 14.6 best score 14.77 epsilon 0.10 steps 774330\n",
            "episode:  350 score:  6.0  average score 14.5 best score 14.77 epsilon 0.10 steps 777076\n",
            "episode:  351 score:  17.0  average score 14.5 best score 14.77 epsilon 0.10 steps 779138\n",
            "episode:  352 score:  17.0  average score 14.5 best score 14.77 epsilon 0.10 steps 781124\n",
            "episode:  353 score:  14.0  average score 14.5 best score 14.77 epsilon 0.10 steps 783621\n",
            "episode:  354 score:  11.0  average score 14.5 best score 14.77 epsilon 0.10 steps 786316\n",
            "episode:  355 score:  10.0  average score 14.4 best score 14.77 epsilon 0.10 steps 788817\n",
            "episode:  356 score:  19.0  average score 14.5 best score 14.77 epsilon 0.10 steps 790595\n",
            "episode:  357 score:  17.0  average score 14.5 best score 14.77 epsilon 0.10 steps 792521\n",
            "episode:  358 score:  16.0  average score 14.6 best score 14.77 epsilon 0.10 steps 794611\n",
            "episode:  359 score:  18.0  average score 14.6 best score 14.77 epsilon 0.10 steps 796675\n",
            "episode:  360 score:  14.0  average score 14.6 best score 14.77 epsilon 0.10 steps 798732\n",
            "episode:  361 score:  15.0  average score 14.6 best score 14.77 epsilon 0.10 steps 801021\n",
            "episode:  362 score:  12.0  average score 14.6 best score 14.77 epsilon 0.10 steps 803563\n",
            "episode:  363 score:  15.0  average score 14.6 best score 14.77 epsilon 0.10 steps 805593\n",
            "episode:  364 score:  18.0  average score 14.6 best score 14.77 epsilon 0.10 steps 807576\n",
            "episode:  365 score:  17.0  average score 14.6 best score 14.77 epsilon 0.10 steps 809625\n",
            "episode:  366 score:  17.0  average score 14.6 best score 14.77 epsilon 0.10 steps 811501\n",
            "episode:  367 score:  19.0  average score 14.7 best score 14.77 epsilon 0.10 steps 813294\n",
            "episode:  368 score:  19.0  average score 14.7 best score 14.77 epsilon 0.10 steps 815094\n",
            "episode:  369 score:  16.0  average score 14.7 best score 14.77 epsilon 0.10 steps 817133\n",
            "episode:  370 score:  17.0  average score 14.8 best score 14.77 epsilon 0.10 steps 819265\n",
            "episode:  371 score:  17.0  average score 14.8 best score 14.77 epsilon 0.10 steps 821398\n",
            "episode:  372 score:  2.0  average score 14.6 best score 14.77 epsilon 0.10 steps 824099\n",
            "episode:  373 score:  19.0  average score 14.6 best score 14.77 epsilon 0.10 steps 825951\n",
            "episode:  374 score:  9.0  average score 14.5 best score 14.77 epsilon 0.10 steps 828423\n",
            "episode:  375 score:  13.0  average score 14.5 best score 14.77 epsilon 0.10 steps 830567\n",
            "episode:  376 score:  16.0  average score 14.6 best score 14.77 epsilon 0.10 steps 832918\n",
            "episode:  377 score:  18.0  average score 14.6 best score 14.77 epsilon 0.10 steps 834836\n",
            "episode:  378 score:  6.0  average score 14.5 best score 14.77 epsilon 0.10 steps 837769\n",
            "episode:  379 score:  19.0  average score 14.5 best score 14.77 epsilon 0.10 steps 839598\n",
            "episode:  380 score:  16.0  average score 14.5 best score 14.77 epsilon 0.10 steps 841520\n",
            "episode:  381 score:  9.0  average score 14.5 best score 14.77 epsilon 0.10 steps 844015\n",
            "episode:  382 score:  12.0  average score 14.4 best score 14.77 epsilon 0.10 steps 846837\n",
            "episode:  383 score:  13.0  average score 14.5 best score 14.77 epsilon 0.10 steps 849029\n",
            "episode:  384 score:  15.0  average score 14.4 best score 14.77 epsilon 0.10 steps 851173\n",
            "episode:  385 score:  17.0  average score 14.4 best score 14.77 epsilon 0.10 steps 853339\n",
            "episode:  386 score:  19.0  average score 14.4 best score 14.77 epsilon 0.10 steps 855077\n",
            "episode:  387 score:  15.0  average score 14.4 best score 14.77 epsilon 0.10 steps 857484\n",
            "episode:  388 score:  15.0  average score 14.4 best score 14.77 epsilon 0.10 steps 859463\n",
            "episode:  389 score:  18.0  average score 14.4 best score 14.77 epsilon 0.10 steps 861440\n",
            "episode:  390 score:  10.0  average score 14.3 best score 14.77 epsilon 0.10 steps 863923\n",
            "episode:  391 score:  13.0  average score 14.3 best score 14.77 epsilon 0.10 steps 866205\n",
            "episode:  392 score:  12.0  average score 14.3 best score 14.77 epsilon 0.10 steps 868497\n",
            "episode:  393 score:  19.0  average score 14.3 best score 14.77 epsilon 0.10 steps 870343\n",
            "episode:  394 score:  20.0  average score 14.4 best score 14.77 epsilon 0.10 steps 872087\n",
            "episode:  395 score:  13.0  average score 14.4 best score 14.77 epsilon 0.10 steps 874319\n",
            "episode:  396 score:  17.0  average score 14.4 best score 14.77 epsilon 0.10 steps 876269\n",
            "episode:  397 score:  5.0  average score 14.3 best score 14.77 epsilon 0.10 steps 878813\n",
            "episode:  398 score:  17.0  average score 14.3 best score 14.77 epsilon 0.10 steps 881007\n",
            "episode:  399 score:  10.0  average score 14.2 best score 14.77 epsilon 0.10 steps 883866\n",
            "episode:  400 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 886034\n",
            "episode:  401 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 888298\n",
            "episode:  402 score:  13.0  average score 14.2 best score 14.77 epsilon 0.10 steps 890484\n",
            "episode:  403 score:  18.0  average score 14.2 best score 14.77 epsilon 0.10 steps 892348\n",
            "episode:  404 score:  15.0  average score 14.2 best score 14.77 epsilon 0.10 steps 894386\n",
            "episode:  405 score:  18.0  average score 14.3 best score 14.77 epsilon 0.10 steps 896395\n",
            "episode:  406 score:  15.0  average score 14.4 best score 14.77 epsilon 0.10 steps 898530\n",
            "episode:  407 score:  13.0  average score 14.3 best score 14.77 epsilon 0.10 steps 900792\n",
            "episode:  408 score:  11.0  average score 14.3 best score 14.77 epsilon 0.10 steps 903312\n",
            "episode:  409 score:  11.0  average score 14.3 best score 14.77 epsilon 0.10 steps 905727\n",
            "episode:  410 score:  14.0  average score 14.3 best score 14.77 epsilon 0.10 steps 908109\n",
            "episode:  411 score:  3.0  average score 14.2 best score 14.77 epsilon 0.10 steps 910862\n",
            "episode:  412 score:  5.0  average score 14.1 best score 14.77 epsilon 0.10 steps 913848\n",
            "episode:  413 score:  11.0  average score 14.1 best score 14.77 epsilon 0.10 steps 916137\n",
            "episode:  414 score:  16.0  average score 14.1 best score 14.77 epsilon 0.10 steps 918154\n",
            "episode:  415 score:  9.0  average score 14.0 best score 14.77 epsilon 0.10 steps 920794\n",
            "episode:  416 score:  19.0  average score 14.1 best score 14.77 epsilon 0.10 steps 922614\n",
            "episode:  417 score:  16.0  average score 14.1 best score 14.77 epsilon 0.10 steps 924733\n",
            "episode:  418 score:  14.0  average score 14.2 best score 14.77 epsilon 0.10 steps 927012\n",
            "episode:  419 score:  13.0  average score 14.1 best score 14.77 epsilon 0.10 steps 929521\n",
            "episode:  420 score:  13.0  average score 14.1 best score 14.77 epsilon 0.10 steps 931802\n",
            "episode:  421 score:  -1.0  average score 13.9 best score 14.77 epsilon 0.10 steps 934976\n",
            "episode:  422 score:  3.0  average score 13.8 best score 14.77 epsilon 0.10 steps 937798\n",
            "episode:  423 score:  8.0  average score 13.8 best score 14.77 epsilon 0.10 steps 940353\n",
            "episode:  424 score:  14.0  average score 13.8 best score 14.77 epsilon 0.10 steps 942533\n",
            "episode:  425 score:  17.0  average score 13.8 best score 14.77 epsilon 0.10 steps 944522\n",
            "episode:  426 score:  16.0  average score 13.7 best score 14.77 epsilon 0.10 steps 946850\n",
            "episode:  427 score:  17.0  average score 13.8 best score 14.77 epsilon 0.10 steps 948927\n",
            "episode:  428 score:  17.0  average score 13.8 best score 14.77 epsilon 0.10 steps 951023\n",
            "episode:  429 score:  17.0  average score 13.9 best score 14.77 epsilon 0.10 steps 953046\n",
            "episode:  430 score:  16.0  average score 13.9 best score 14.77 epsilon 0.10 steps 955091\n",
            "episode:  431 score:  10.0  average score 13.9 best score 14.77 epsilon 0.10 steps 957505\n",
            "episode:  432 score:  19.0  average score 13.9 best score 14.77 epsilon 0.10 steps 959354\n",
            "episode:  433 score:  16.0  average score 13.9 best score 14.77 epsilon 0.10 steps 961433\n",
            "episode:  434 score:  15.0  average score 14.0 best score 14.77 epsilon 0.10 steps 963645\n",
            "episode:  435 score:  18.0  average score 14.0 best score 14.77 epsilon 0.10 steps 965864\n",
            "episode:  436 score:  19.0  average score 14.1 best score 14.77 epsilon 0.10 steps 967610\n",
            "episode:  437 score:  12.0  average score 14.0 best score 14.77 epsilon 0.10 steps 969849\n",
            "episode:  438 score:  18.0  average score 14.1 best score 14.77 epsilon 0.10 steps 971809\n",
            "episode:  439 score:  10.0  average score 14.1 best score 14.77 epsilon 0.10 steps 974142\n",
            "episode:  440 score:  20.0  average score 14.1 best score 14.77 epsilon 0.10 steps 975847\n",
            "episode:  441 score:  18.0  average score 14.1 best score 14.77 epsilon 0.10 steps 977688\n",
            "episode:  442 score:  14.0  average score 14.1 best score 14.77 epsilon 0.10 steps 980109\n",
            "episode:  443 score:  18.0  average score 14.1 best score 14.77 epsilon 0.10 steps 982061\n",
            "episode:  444 score:  17.0  average score 14.2 best score 14.77 epsilon 0.10 steps 984056\n",
            "episode:  445 score:  13.0  average score 14.2 best score 14.77 epsilon 0.10 steps 986247\n",
            "episode:  446 score:  7.0  average score 14.2 best score 14.77 epsilon 0.10 steps 988579\n",
            "episode:  447 score:  12.0  average score 14.1 best score 14.77 epsilon 0.10 steps 990784\n",
            "episode:  448 score:  16.0  average score 14.1 best score 14.77 epsilon 0.10 steps 992878\n",
            "episode:  449 score:  14.0  average score 14.2 best score 14.77 epsilon 0.10 steps 995386\n",
            "episode:  450 score:  17.0  average score 14.3 best score 14.77 epsilon 0.10 steps 997307\n",
            "episode:  451 score:  11.0  average score 14.2 best score 14.77 epsilon 0.10 steps 999557\n",
            "episode:  452 score:  9.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1002177\n",
            "episode:  453 score:  19.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1003976\n",
            "episode:  454 score:  10.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1006367\n",
            "episode:  455 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1008260\n",
            "episode:  456 score:  14.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1010388\n",
            "episode:  457 score:  17.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1012273\n",
            "episode:  458 score:  19.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1014045\n",
            "episode:  459 score:  18.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1015897\n",
            "episode:  460 score:  19.0  average score 14.3 best score 14.77 epsilon 0.10 steps 1017901\n",
            "episode:  461 score:  16.0  average score 14.3 best score 14.77 epsilon 0.10 steps 1019904\n",
            "episode:  462 score:  13.0  average score 14.3 best score 14.77 epsilon 0.10 steps 1022192\n",
            "episode:  463 score:  7.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1024878\n",
            "episode:  464 score:  17.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1026862\n",
            "episode:  465 score:  7.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1029767\n",
            "episode:  466 score:  13.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1031979\n",
            "episode:  467 score:  13.0  average score 14.0 best score 14.77 epsilon 0.10 steps 1034286\n",
            "episode:  468 score:  19.0  average score 14.0 best score 14.77 epsilon 0.10 steps 1036159\n",
            "episode:  469 score:  13.0  average score 14.0 best score 14.77 epsilon 0.10 steps 1038636\n",
            "episode:  470 score:  19.0  average score 14.0 best score 14.77 epsilon 0.10 steps 1040423\n",
            "episode:  471 score:  16.0  average score 14.0 best score 14.77 epsilon 0.10 steps 1042574\n",
            "episode:  472 score:  16.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1044604\n",
            "episode:  473 score:  13.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1047102\n",
            "episode:  474 score:  17.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1048975\n",
            "episode:  475 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1051088\n",
            "episode:  476 score:  15.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1052987\n",
            "episode:  477 score:  15.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1055179\n",
            "episode:  478 score:  9.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1057754\n",
            "episode:  479 score:  12.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1060250\n",
            "episode:  480 score:  15.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1062291\n",
            "episode:  481 score:  15.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1064479\n",
            "episode:  482 score:  15.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1066723\n",
            "episode:  483 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1068878\n",
            "episode:  484 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1070894\n",
            "episode:  485 score:  15.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1073042\n",
            "episode:  486 score:  18.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1074951\n",
            "episode:  487 score:  9.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1077439\n",
            "episode:  488 score:  18.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1079294\n",
            "episode:  489 score:  13.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1081410\n",
            "episode:  490 score:  18.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1083243\n",
            "episode:  491 score:  15.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1085298\n",
            "episode:  492 score:  13.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1087409\n",
            "episode:  493 score:  14.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1089584\n",
            "episode:  494 score:  19.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1091548\n",
            "episode:  495 score:  12.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1093689\n",
            "episode:  496 score:  16.0  average score 14.1 best score 14.77 epsilon 0.10 steps 1095864\n",
            "episode:  497 score:  14.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1098227\n",
            "episode:  498 score:  16.0  average score 14.2 best score 14.77 epsilon 0.10 steps 1100107\n",
            "episode:  499 score:  15.0  average score 14.3 best score 14.77 epsilon 0.10 steps 1102132\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEGCAYAAAA5T6EkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZwcVZ3v8U/PJAOdBCoTg4qZsBU0uiAbUWcR1r0re8OyYAUQdo3AckXJEr2CLAaVQrxYr7C7t0BAcUU0CgZ1lR1XhJDiSXJFVkhWJoKzgKIIBUl05SFJIUnMJKHvH1Wd9PT0Q/VDdXd1f9+v17ymu6q6+1RP0r8+p36/czK5XA4REZFO19fuBoiIiMShgCUiIqmggCUiIqmggCUiIqmggCUiIqkwpd0NqNXs2bNzpmm2uxkiIqmyfv36F3K53EHtbkcjUhewTNNkdHS03c0QEUmVTCbzTLvb0CgNCYqISCooYImISCooYImISCokdg3LtL0bgUXAc75rHVFifwa4Fng3sB34gO9aP02qPSIikm5J9rBWAidU2H8iMD/6WQpcn2BbREQk5RILWL5r3Q9srnDIKcA3fNfK+a61Dphp2t7BSbVHJPXGRuBzR4AzM/w9NtLuFvUGve8do53XsOYAGwrub4y2iUixsRG4/QIINgC58PftF+z78EzLh2pa2plX6n2/ZSmsXtbulvWkVNRhmba3lHDYkL5t43U9x6i/mTW/eI5P/vWbyGQyzWyeSLLGRuD7H4LcKxO379oBt5wb/hQKNoTbnl0Hi65pXTuryX/479oR3s8HXYAFi9vXrkrWLN/X3r1yMHojHHJ057a7S7Wzh7UJmFtwfyjaNonvWit81xr2XWt41vSBul5sbGPA9ff9mi3bd9X1eJG2GBuB7394crCKY/SGzurBlPrw37Uj3N6pgg1lduQ6u91dqp0BaxXwftP2MqbtHQ0Evmv9NqkXGxrMArBxy/akXkKk+VZfCLk99T/+zoub15ZGlfvwDzaAY8AV8zorwI6NABVGY8oGM0lKkmnt3wGOBWabtrcR+AwwFcB3rS8DdxCmtD9JmNb+waTaAjA0OA2AjVt2sGBoZpIvJVK/sZEwyOyolK9Ugx2bw+ds99DV3g//Ciuc79gMt50X3m53eyHqQVVZkf2fXweLPt8Z7e0BiQUs37XOqLI/B5yX1OsXm6MelnSCsZHwgzDYCMYQLLxs34fd6mXhMF6z3X5h+z9Q77yYqh/+AHvGw2NraW+l97QRwcbqx4xvC4Pss+vgV/dUb8PqZeH1r/x7MTA9DHgw+YtKdhaceEXr/naOsbd2Fic4ItrmAOcCz0dHfQonuKM1DZosFUkXzWBkp3Lg/lPYuKX4AqpIi9x0Mjz9o333gw1w60fg1vPglfqSiWLZta29vayxkdp6jDs2hx/sxQkjpQLTw98q/Z5C4+drDMUb9tszPvGLRj6TsDDpZWyk9N95fFt4bKZv8tDvjs37kmqys6JtW5oblCdaCXwR+EbR9s/hBFc1+8Xq0TMBC8JhQQUsaYvVyyZ+sOa90qIkoHb2suq5jjZ6Q/hT2AO57bwwOMC+oFCq1/bKruac7/zjG+jx5vY99pCjo8SZctcic9WvUxYG/KSyK53gfhzDbN4TNl+PBaws/ovb2t0M6UbVhqXWf719bYOwl+UY4e1WDzU1cj1ufFvYw8j0lciUrDDEuGtb6V5aLX51T/2PzcsH3mbLZ1fW8De86JiB2ThG4dpMK3CCFTEeej6O8X5gFLgIJ9hSY2ubpscC1jR+/OQL5HI51WJJ/YqD0/zj4eFvFn37L6iDGhupLy29nKnTww/kvHwAgsk1WaUUJzeUOp/C6zF7729gQuJEnMDXrKy/etP6G6mV6vQswDjX2ApcvXb8hase3Dlc46tcD1xO+Ee/HLgaOKfG52iaHgtYWbaP72HL9l3UW88lPaxUUkSwofw36Py360wTq0eGl1TuNTy7Lt43+nxyA0wu5i2+HjPh+Qp6NeWy+sZGwiG5XR0wmlHr0ODe4N3hwQrCLxNJc4Lf7bttfBVYnfyLltdTy4uoFkvq1kgGXyO9q4HpQAaMuXDaV6sPcS26Jn6A3LE5rPOaNJNDDfaMTyygHRuBWz4UL1gNTK//dePKJ5zEMWEapgoy/Y23qxkWXpb8azhG4fyupwKPJv+i5fVYD0u1WFKn9Stb/IIZGD6nvmswb/9g/OA63oReULAhLPqt6VpVBj71m/BmUun8eXHT5EtOw1TCqV9ufw9y3ruafw3SMfbWzuIY+drZY3GMIwm71j7woea+aG16KmCpFktqlh8iamS2ibjyiQXG3MbSlhddA2M3NycYxVVzYkXB0GI+KBfWJzVT3OLpOMOAmf7weRYsTjjQ9gEleuaZvvALSRJzRDpBqdrZBL9J1K6nApZqsaQmxZO1NpsxFz6W0AjLos/HS8BoF2PuxPuLrgkTJJK6fnTL0ijbsD/88lH8pSDusGHhF5d6A+28d8Gm0cpfKE77SvuLvTtQT13DAtViSQ3iDhHVK8lrEAsWhwkanarUuS9YHAZwJwh/+veL/3zZWWEgKCsKKPmAU7w8S9xasVKB9rQV0fbMvgLfcoaXwNmrotqyMpnKw0sUrMroqR4WqBZLalBj2nBNWvGhlHSvpV5xr7+c8sUKvcQMOFsnb67lWlphLVPcx5QLtIXnU26ocN679vXK8scXXgtLcrivS/RgwFItlsSUHaz92kymH8w/B//Hpa97tbpot/DDtNFrLvPeBa96Q/3PUesH8oLF5ScCLpfSfeIVtQ2F1vKlJO6XjPz5rV8Z/hvI9MPbPzD5vIsDnVTVcwFrjmqx0impCU6bqdXBqFZ7r7lUCDhTs3DSF8Lb5d7vF58sPc1UOdVqxyo58YrJ1xGnZssPpy5YXHqxy3KMoerXr/LTQ9Xyd110jXpKCei5gJWvxdq0ZYcCVloUz3DdqpVqq/WusrPg4qeTe/0kTBgm3Bj2IqH0pKrl3tuzV8XrrdXzQV8s/9havqzUkta/8LLKCzE2Emyl6Xo2YG3csp0/GTLa3BqpqtwHY355+DXLk+ltVfvW3Td133RIadOMoah84CuVRdnsnmat7V10TbxeYF9UAFzp+p6CVUfpySxBQJmCaTA2Uv2bcn45iXyAGRuBzx0Bzszwd6nAU+2Y1csqXwfJzoL3fKlzh/5aZcHicPgwnyGXn43j4qfb/96cvar6Ma/sCZMeyinOCJS267kelpGdygH7T1HxcBpUGqoplF9OAibPi3fL0nDNpM1P7RsCG3954kS1hcOLcYa60jYMmKROThww5lbPjqw0W8X845vbHmlYz/WwQLVYqVFLBteubWXmxcuFQ0PBhvD2js37gtXex+4I1ytyjGSnCJLWWnhZmKBRr2YsLyJN1aMBK6uAlQa1zkbdyFREcadeqlYYKp1jwpBlHZKsw5O69HDA2k4ul8C8ZdI8nTgkk9ZEi15VOHtGrVqxfIfUpEcD1jS2je9h6/YWLU8utRsbCRdF7CSaMifdaulpVar1krbpuaQLKExt38GgarHaa2xk4mwG+RnLSy6JDvQNwCvjk7cnKhPOF6dglW4LLwuTcKpNVJvpD4cS9ffuOD3aw9IyIx1hbCRMSS8s0M0HqXIzFbwyXt/wTiMUrLrDgsXhGmPVnPpl/b07VI/2sFSLVVW5qZDiTpFUapn0/MwHUH6OuLjyy0QkTcOA3aVaUXESCyNK0/RkwFItVhXF60AFG8JC2vuvhuCZidtLTZFUrpZpfFvjazTls/SSDlbNmFZIOlPJqaUaWOFZWqYnAxaoFquicutAvfCLydsKl2iA5Jc7z2fpVS0KzRB7Ub3srNJz6Un30uS0qdTDASvLsy+qhzVB8SSzcQUbwimOWrHmUj6YLLys8jx2EF4fe6VKJmgaJ7AVSYJj3AgsAp7DCY6Its0C/g0wAR9YjBNsaVMLezPpAlSLNcnenlGd70erFwisNo/dgsXhfH+VCn2nZlVXJbLPSuCEom02sAYnmA+sie63TQ/3sPbVYim1nXCxuU5XHHyqzWNXvD8Na2qJtIsT3I9jmEVbTwGOjW7fBNwHXNy6Rk3UwwFLtVgTtCLjrhF9/Y33hjp5olaRhF10zMBsHGO0YNMKnGBFlYe9Bif4bXT7v4HXJNO6eHo2YM2ZGS3kuFXrYgHlC3VbpXANpeJi4k5fyVckBa5eO/7CVQ/uHK77CZwgh2O09RpKzwasuarF2mdsBNpyLa/MDBLqCYl0it/hGAfjBL/FMQ4GnmtnY3o26eLA7BQO2G9KbwWscgsX3nkxZZMtsrPC4tlGZinvmwr9RcOuU7OaQUKk860Czo5unw3c1sa29G4PK5PJMCfKFOwJ5YqBV19YeVmOfMp3Yc1K8XNVkukPs/VACQ8incwxvkOYYDEbx9gIfAZwgREcYwnwDNDW/7Q9G7AgXzzcAwFrbKT8pJ/1rCGVDzT5AJTJlLn+lZk4L5sClEjncoIzyuxZ2NJ2VNCzQ4KwbyHHrq7FGhuBWz5EXfVVlYYB964ztBVO/UqJlV2jqW4UpESkSRLtYZm2dwJwLdAPfM13Lbdo/yGEuf0zo2Ns37XuSLJNhYYGs7y8czfBjl3MnNalqe1rlgN1ZP9lakgjL+5xachPRBKQWA/LtL1+4DrgROBw4AzT9g4vOuzTwIjvWm8FTge+lFR7SumJWdvrXeZ7f6O2gFPY4/rYowpWItJ0SQ4JHgU86bvWU75rjQM3E1ZNF8oBB0a3DeA3CbZnkp5YF6veZb53tG26MBGRkpIcEpwDFE4wtxF4R9ExDnCPaXsfBaYDx5V6ItP2lgJLAfq2NW+12Z6oxZp/fH2zp9cb6EREEtLupIszgJW+aw0B7wa+adrepDb5rrXCd61h37WGZzVxGqWursUaG4Er5tUXrKZmw2tQIiIdJMmAtQmYW3B/KNpWaAkwAuC71lpgf2B2gm2aoGtrsUotPV9VJvxlzA1nQdc1KBHpMEkOCT4EzDdtbx5hoDodOLPomGcJc/xXmrZ3GGHAej7BNk3SlbVYa5bHWwdqYLqy+kQkNRILWL5r7TZt73zgbsKU9Rt913rMtL3lwKjvWquAi4Cvmrb3McIEjA/4rtXSoqihwSzrnnqRXC5HJpNp5UsnJ05moCaTFZGUSbQOK6qpuqNo22UFtx8H3plkG6rpylqs7GDl4cDsLAUrEUmddiddtF1P1GIV6h/QKrsikkoKWN1Yi1Wpd3XKdepdiUgqKWAVrDzcFVYvK7/PmKtgJSKp1fMBy8hOZUa31GKtXlah7iqj2ioRSbWeD1iZTGbvrO2pNjYCozdWOCCn3pWIpFrPByzILzOS8mtYa5ZTcQkRY275fSIiKaCARZgpuCnt62JVrL3ScKCIpF9PrzicNzSY5fc7d/PSjt0Y06a2uzn1MYbCZe9L0UKKIhKHY/jA74E9wG6cYLi9DZpIPSz2ZQpuSPOw4MLLwhqrYsNLYNE1rW+PiKTVX+IER3ZasAIFLKBLioefXQd7ipZe6ZsKhxzdnvaIiDSZAhZdUDxcLkPwlV1RMoaISCw54B4cYz2OsbTdjSmma1h0QS1WpQzBOBPhikjXu+iYgdk4xmjBphU4wYqiw/4cJ9iEY7wa+AGO8Quc4P4WNrMiBSy6oBarUlDSysEiAly9dvyFqx7cWfm6lBNsin4/h2N8HzgK6JiApSHBSKprscoGJaWzi0hMjjEdxzhg7204Hni0rW0qooAVSXUt1sLLwmXtJ8gonV1EavEa4Mc4xs+AnwAeTnBXm9s0gYYEI6mvxZqShV3RkGZ2lhZoFJHaOMFTwFva3YxKFLAihbVYxjSjza2pweplUYZgQc9wd0qvxYmIVKAhwUgqa7H2prMXDWPu2qF0dhHpOgpYkVTWYimdXUR6iAJWxMhOZfpAP5u2pqiHpXR2EekhCliRsBZrWrqGBJXOLiI9RAGrQOqKh5XOLiI9RAGrQOqKhxcshrecCZn+8H6mPwxWmp1dRLqQAlaBocFp/P4Puwl27Gp3U+IZG4GffRtye8L7uT3h/bGR9rZLRCQBClgFUpcpuGb5vmLhPKW0i0iXUsAqkLparHJZgkppF5EupIBVYF8PKyUBKztYertS2kWkCylgFZg5LazFSsWQ4NgI7Pz95O39A0ppF5GupIBVIFW1WGuWhysKFxuYoZR2EelKClhFUlOLVe461Y4trW2HiEiLKGAVSU0tVrnrVLp+JSJdSgGrSGpqsUrNcjE1q+tXItK1FLCKpKoWa0pBwMrOgpO+oOtXItK1FLCKpKIWa2wEbr8Admzet02LNopIl9OKw0VSUYtVaYYL9bBEpB6OcQJwLdAPfA0ncNvcokkSDVim7U14A3zXmvQGmLa3GHAIVyL8me9aZybZpmpSUYulGS5EpJkcox+4DvgrYCPwEI6xCid4vL0NmyhWwDJt7zTgCuDVQCb6yfmudWCFx0x6A0zbW+W71uMFx8wHLgHe6bvWFtP2Xl33mTRJvhZrUyf3sIwhCDaU3i4iUrujgCdxgqcAcIybgVOA9AUs4ErgJN+1fl7Dcx8FPOm71lMApu2VegPOBa7zXWsLgO9az9Xw/ImZ0+m1WAsvC69hFQ4LKkNQRCq46JiB2TjGaMGmFTjBiuj2HKDwW/BG4B0ta1xMcQPW72oMVhDvDXgjgGl7DxAOGzq+a91V/ESm7S0FlgL0bRuvsRm1GxrMMupvrn5guyxYDM+ug/UrwyVFMv3huli6fiUiZVy9dvyFqx7cOdzudjQibsAaNW3v34BbgZ35jb5r3dKE158PHAsMAfebtvcnvmttLTzId60VwAqA4Xs/k2vwNasaGszyUlSLZWSnJv1ytSu3DtYhRytoiUg9NgFzC+4PRduS4RhZ4BCc4IlaHhY3rf1AYDtwPHBS9LOoymPivAEbgVW+a+3yXetp4JeEAayt8qntHXsdS+tgiUhzPQTMxzHm4RgDwOnAqkReyTFOAh4B7oruH4ljxHqtWD0s37U+WEezHgLmm7Y3jzBQnQ4UZwDeCpwBfN20vdmEQ4RP1fFaTVVYPHz468rmlbSPsgRFpJmcYDeOcT5wN+HlmRtxgseSejXCHIf7otd+BMeYF+eBcbMEh4B/Ad4ZbfoP4B981yr7Cem71m7T9ia8Ab5rPWba3nJg1HetVdG+403bexzYA3zCd60X47QpSR1fPKwsQRFpNie4A7ijBa+0CycIcIzCbbEu9cS9hvV14NvAe6P7Z0Xb/qrSg3zXmvQG+K51WcHtHLAs+ukYg9OmMm2gv3MD1vzjYfRGJvyNlSUoIunwGI5xJtCPY8wHLgAejPPAuAHrIN+1vl5wf6VpexfW2MjUCGuxOnTW9nzCxYQvJBllCYpIWnwUuJQwge/bhCNt/xjngXED1oum7Z0FfCe6fwbQ9qG7JHXsQo6lEi7Iwa/uaUtzRERiC2fU8HCCvyQMWjWJmyV4DrAY+G/gt8DfAvUkYqRGx/awlHAhImnlBHuAV3AMo+qxJcTNEnwGOLmeF0irjq3FUsKFiKTby8B/4Rg/ALbt3eoEF1R7YMWAZdrev1Ahe8N3raovkFaFtVgdFbA0LZOIpNst0U/NqvWwRqvs71odXYs1JbsvYGVnwYlXKOFCRNLBCW6KipPfGG15AieItcR7xYDlu9ZNjbYtrTqyFiu/cGNh70oLN4pImjjGscBNgE+48sdcHONsnOD+ag+tNiT4ed+1LjRt73ZKDA36rtW117U6shZLCzeKSPpdDRy/dx5Bx3gjYQb626s9sNqQ4Dej31c10ro06sharFLJFqAMQRFJk6kTJr11gl/iGLESBaoNCa6Pfv8ov820vUFgru9aY/W1NT2GBqexaWuH9LDGRojWzZy8TxmCIpIeozjG14BvRff/jpj5EnHnEryPMK19CrAeeM60vQd81+qoKZWabc7MLOuf2dLuZoTWLKd0wmZGGYIikib/GziPcEomCOem/VKcB8YtHDZ813oJOA34hu9a7wCOq7WVaTM0mCXYsYuX/hArgSVZZYf9crp+JSJpMgW4Fic4DSc4DfgC4QTpVcUNWFNM2zuYcLaL1fW1MX06al2scsN+xtzS20VEOtMaIFtwPwvcG+eBcQPWcsIJCn/tu9ZDpu0dCvyqpiam0L5arA4IWAsvCwuEC6lgWETSZ3+c4OW998Lb0+I8MO7UTN8Fvltw/yngb2prY/oUFg+3XX7Yb83ycHjQGAqDlYYDRSRdtuEYb8MJfgqAYwwDsXoFcZMuDgWuBY4mvPK/FvhYFLi61qzpA2SndlgtlohIul0IfBfH+E10/2DgfXEeGHdI8NvASPTEryPsbX2n4iO6QEfVYuVnuQg2ALnw9+0XROnuIiIdzjH+FMd4LU7wEPDHwL8Bu4C7gKfjPEXc9bCm+a71zYL73zJt7xM1NTalwoDVAT0szXIhIu3iGA5wLvB8tOVTOMEd5R9Q0lfYl11+DPApwsUcjwRWEC5bVVHcgHWnaXs2cDPhkOD7gDtM25sF4LvW5tranR5Dg9P46bNb290MrYMlIu32OZygkVmP+nGCfKx4H7ACJ/ge8D0c45E4TxA3YOW/wn+oaPvphAHs0JjPkzqFtVgH7t/GZUa0DpaIpFs/jjEFJ9gNLASWFuyLFYviZgnOq6NxXaGwFuvAg9sYsLQOlog04KJjBmbjGIVTIK3ACVbU8BTn4xjvJ5xG6SKcoNZpgL4D/AjHeIEwK/A/AHCMNwBBnCeoNlv7J33XujK6/d4ovT2/75991/pUjQ1OncJarMMObvO6WFoHS0TqdPXa8ReuenDncNkDHONe4LUl9lwKXA9cTjiidjnhjOvn1NQAJ/gnHGMNYfLePThBfq65PsJrWVVV62GdDlwZ3b6Eglos4ATCi2ZdrSNqsbQOlogkzQniTbfnGF+l3hmPnGBdiW2/jPvwamntmTK3S93vSh1Ri1UpQ1BEJGmOcXDBvVOBR9vRjGo9rFyZ26Xud6WOqMVShqCItNeVOMaRhJ/7PpMT8FqiWsB6i2l7LxH2prLRbaL7+yfasg7S9losZQiKSDs5wf9qdxOg+gKOsaZ873ZDg9N4eEMba7HmHw+jNzKhU6sMQRHpMXGnZuppcwazbN2+i9+3Y12ssRH42beZOAKbgbecqQxBEekpClgx5DMFN21tw7BgqYQLcvCre1rfFhGRNlLAiiFfPLxxcxsClhIuREQABaxY2lqLlR0svV0JFyLSYxSwYnjV9AH2n9rX+kzBsRHY+fvJ2/sHlHAhIj1HASuGsBZrWusD1prl8EqJRI+BGUq4EJGeo4AV09Bglo1bWzwkWO461Y5a55wUEUk/BayY2lI8XO46la5fiUgPirseVl1M2zsBuBboB77mu5Zb5ri/Af4d+FPftUZLHdNuQ4PT9tZiHdCqdbFUMCwisldiPSzT9vqB64ATgcOBM0zbO7zEcQcA/wD8Z1JtaYaW12KpYFhEZIIkhwSPAp70Xesp37XGgZuBU0ocdzlwBfCHBNvSsJbXYqlgWERkgiSHBOcAhTO2bgTeUXiAaXtvA+b6ruWZtveJck9k2t5SouWU+7aNJ9DU6lpei6WCYRGRCRK9hlWJaXt9wDXAB6od67vWCmAFwPC9n2nLsiYtr8XSDO0iIhMkOSS4CZhbcH8o2pZ3AHAEcJ9pez5wNLDKtL3ySzi3UctrseYfX9t2EZEul2QP6yFgvml78wgD1enAmfmdvmsFwOz8fdP27gM+3qlZgtDiWqzHvl96u65hiUiPSqyH5bvWbuB84G7g58CI71qPmba33LS9k5N63SQNDWbZ1Ioe1tgI7Nhcep+uYYlIj0r0GpbvWncAdxRtK1lE5LvWsUm2pRmGBqexZfsuXt65mxn7JfjWrVlefp+uYYlIqznGewEHOAw4CicYLdh3CbAE2ANcgBPcnVQzNNNFDfbWYiXdyyqVbJGnomERab1HgdOA+ydsdYzDCS/3vBk4AfgSjpHYSvUKWDWYM7MFqe1jI0Cm9L7sLBUNi0jrOcHPcYInSuw5BbgZJ9iJEzwNPElYg5uItqW1p9He4uEke1hrljNxdou8DJx4RXKvKyJd7aJjBmbjGIVJbStwghUNPu0cYF3B/Y3RtkQoYNVg9owB9pvSl2wPq2xSRU69KxGp29Vrx1+46sGd5cuGHONe4LUl9lyKE9yWWMNqoIBVg7AWK+FZ27ODpTMEjbmTt4mINIsTHFfHo6rV2zaVAlaNEi0e1grDIpIuq4Bv4xjXAK8D5gM/SerFlHRRo7CHldCQoFYYFpFO5Bin4hgbgWMAD8cIU9ed4DFgBHgcuAs4DyfYk1Qz1MOqUaK1WOXS2bXCsIi0kxN8Hyg9/Y4T/BPwT61ohnpYNUqsFqtSOruKhUVEFLBqldgyI5XS2XX9SkREAatWidVilZ3dQunsIiKggFWzRGqxKg4HKp1dRAQUsGrW9FqssRH4/ofQcKCISGUKWHVoWi3W2Ajc+hHIvVLmAA0HiojkKWDVoWm1WOXqrvI0HCgispcCVh3ytVjbdu5u7ImqLcao4UARkb0UsOqwtxZra4PDgpXqq7SUiIjIBApYdWhaLdb840tv7x/QUiIiIkUUsOowZ2/AaqCHNTYCD39z8vaB6XDKdepdiYgUUcCqw0Ez9otqsRoIWHdeDHvGJ2/v30/BSkSkBAWsOmQyGeY0milYas2rSttFRHqcAladGqrFGhtpbmNERHqAAladGprt4s6Ly+/LzqrvOUVEupwCVp2GBrNs3jZeey3W6mWVh/2UHSgiUpICVp3ys7bXVIs1NgKjN5Tfr9orEZGyFLDqVHMt1tgI3HJu5WPUuxIRKavJa7z3jqG4tVhjI3D7hbBrW/UnVe9KRDqRY7wXcIDDgKNwgtFouwn8HHgiOnIdTvDhpJqhgFWnqrVYtQQqULKFiHSyR4HTgK+U2PdrnODIVjRCAatOZWuxxkbg1vPglRJFwZVoOFBEOpUT/Dz8bbS1GQpYDZhUizU2Ard8CCi3vlUZw0s0HCgiibromIHZOMZowaYVOMGKJjz1PBzjYeAl4NM4wX804TlLUsBqwNBglkc3Bfs23HkxdQWrRdc0tV0iIsWuXjv+wm7/jV8AAA4iSURBVFUP7hwue4Bj3Au8tsSeS3GC28o86rfAITjBizjG24FbcYw34wQvNd7iyRSwGpCvxdo+vptpv7il9mmVFKxEpFM4wXF1PGYnsDO6vR7H+DXwRmC00sPqpbT2Buytxdqyo/LsFcUGpsNpX1WwEpF0c4yDcIz+6PahwHzgqaReTj2sBuRT2/e/55PxelfZWWFyha5XiUiaOMapwL8ABwEejvEITvDXwF8Ay3GMXYTXQz6MEyQ2g3cml8sl9dyJGB4ezo2OJtLbrFnwk39lYPVH2b9vD5lKB06dDpf+plXNEhGZJJPJrM/lcuWvYaWAelj1Wr2MA0dvIFNtULV/AE76fEuaJCLSzRINWKbtnQBcC/QDX/Ndyy3avwz4e2A38Dxwju9azyTZpqYYG4HRGyv3qvK0erCISFMklnRh2l4/cB1wInA4cIZpe4cXHfYwMOy71gLg34Erk2pPU62+EIgxlKrJbEVEmibJHtZRwJO+az0FYNrezcApwOP5A3zX+mHB8euAsxJsT3OsXgbjMaZbyvRr9goRkSZKMmDNATYU3N8IvKPC8UuAO0vtMG1vKbAUoG9bjVMeNdv6ldWP6d8PTvmielciIk3UEUkXpu2dBQwD7yq133etFcAKgOF7P9OetMb8ZLa5PZWPUzGwiEgikgxYm4C5BfeHom0TmLZ3HHAp8C7ftXYm2J76jY3ALUupet3KmKtgJSKSkCQD1kPAfNP25hEGqtOBMwsPMG3vrYTT1Z/gu9ZzCbalMXdeTLVg9Uqmn76Fl7WmPSIiPSixLEHftXYD5wN3Ey7wNeK71mOm7S03be/k6LDPAjOA75q294hpe6uSak9DqsxikcvB7fP+j65ZiYgkSDNdVBNjafv/zhzE5W8Y4bq/e1uLGiUiUhvNdNELbju/8v6+fm6Zec7khRxFRKSpNFt7JTedDHsq5IH07wfv+TIbhk6auJCjiIg0nXpY5YyNwNM/qnzM/wnzRIZefJIX8+tiDegtFRFJgnpY5VQbCszO2nszv8zIJvWyREQSo4BVyupllYcCYcK0S/mFHDduVcASEUmKAlYpozdU3j/vXRNS2OdGPSxdxxIRSY4CVrGr/rjy/r4BOHtiudjsGfsxMKVPmYIiIglShkBejHorAN5z3aRNfX0ZhmZm1cMSke7kGJ8FTgLGgV8DH8QJtkb7LiGcvHwPcAFOcHdSzVAPC+IHq76BsrNZzBlUwBKRrvUD4AicYAHwS+ASABzjcMJp994MnAB8CcfoT6oRvdPDWr2s+rWpakr0rvKGBrP84PHfNfb8IiKdyAnuKbi3Dvjb6PYpwM04wU7gaRzjScK1ENcm0Yze6GE1I1gVJVoUGxqcxgsvj7NjvMryIyIi6XYO+9YuLLXu4ZykXrg3eliNBqsZB09KtCi2txZr63be8OoDGns9EZEmu+iYgdk4RuFErCtwghV77znGvcBrSzz0UpzgtuiYS4HdwL8m2NSyeiNgNWI/Az7+i6qH5WuxnnlRAUtEOs/Va8dfuOrBneUnv3WC4yo+gWN8AFgELMQJ8rOmx1r3sFl6Y0iwXn0DcMmzsQ59/UHTAfj18y8n2SIRkdZzjBOATwIn4wSF9TurgNNxjP1wjHnAfOAnSTWj+wPW2EidD8xUTLIoNnPaALNnDPDkcwpYItJ1vggcAPwAx3gEx/gyAE7wGDACPA7cBZyHEyR2Ib/718P63BEQbKh+XKG+KfCe62tekPF9X1nLf20KmDMzW9vriYjEcMHC+Zz0ltfV9Vith5UGwcbqxwwvgUXXNPxSS//iUL730xivJyJSByM7td1NaKvuD1jGUOkeljEXPvZoU19q4WGvYeFhr2nqc4qISKj7r2EtvAymFg3RTc2G20VEJDW6P2AtWAwnfSHsUZEJf5/0hZqvT4mISHt1/5AghMFJAUpEJNW6v4clIiJdQQFLRERSQQFLRERSQQFLRERSQQFLRERSIXVTM2UymeeBZ+p5bN+0mbNf2b71hSY3qSN087lBd5+fzi2dUnhuf5TL5Q5qdyMaksvleubnjy5ePdruNujcdH46t+746eZz69QfDQmKiEgqKGCJiEgq9FrAWlH9kNTq5nOD7j4/nVs6dfO5daTUJV2IiEhv6rUeloiIpJQCloiIpEJXztZu2t4JwLVAP/A137Xcov37Ad8A3g68CLzPdy2/1e2sR4xzWwb8PbAbeB44x3etuurWWq3auRUc9zfAvwN/6rvWaAub2JA452fa3mLAAXLAz3zXOrOljaxTjH+XhwA3ATOjY2zfte5oeUPrYNrejcAi4DnftY4osT9DeO7vBrYDH/Bd66etbWVv6Loelml7/cB1wInA4cAZpu0dXnTYEmCL71pvAD4HXNHaVtYn5rk9DAz7rrWA8EP9yta2sj4xzw3T9g4A/gH4z9a2sDFxzs+0vfnAJcA7fdd6M3Bhyxtah5h/u08DI75rvRU4HfhSa1vZkJXACRX2nwjMj36WAte3oE09qesCFnAU8KTvWk/5rjUO3AycUnTMKYTf9iD8UF8YfUvqdFXPzXetH/qutT26uw4YanEb6xXn7wZwOeEXjD+0snFNEOf8zgWu811rC4DvWs+1uI31inNuOeDA6LYB/KaF7WuI71r3A5srHHIK8A3ftXK+a60DZpq2d3BrWtdbujFgzQE2FNzfGG0reYzvWruBAHhVS1rXmDjnVmgJcGeiLWqequdm2t7bgLm+a3mtbFiTxPnbvRF4o2l7D5i2ty4aZkuDOOfmAGeZtrcRuAP4aGua1hK1/r+UOnVjwBLAtL2zgGHgs+1uSzOYttcHXANc1O62JGgK4bDSscAZwFdN25vZ1hY1zxnASt+1hgiv9Xwz+puKxNaN/2A2AXML7g9F20oeY9reFMIhihdb0rrGxDk3TNs7DrgUONl3rZ0talujqp3bAcARwH2m7fnA0cAq0/aGW9bCxsT5220EVvmutct3raeBXxIGsE4X59yWACMAvmutBfYHZrekdcmL9f9SGteNWYIPAfNN25tH+I/mdKA402oVcDawFvhb4P/5rpWGCuqq52ba3luBrwAnpOgaCFQ5N9+1Ago+4Ezbuw/4eIqyBOP8u7yVsCfyddP2ZhMOET7V0lbWJ865PQssBFaatncYYcB6vqWtTM4q4HzT9m4G3gEEvmv9ts1t6kpd18OKrkmdD9wN/JwwM+kx0/aWm7Z3cnTYDcCrTNt7ElgG2O1pbW1inttngRnAd03be8S0vVVtam5NYp5basU8v7uBF03bexz4IfAJ37U6vucf89wuAs41be9nwHcIU7/T8CUR0/a+Q/jl9k2m7W00bW+JaXsfNm3vw9EhdxB+sXgS+CrwkTY1tetpaiYREUmFruthiYhId1LAEhGRVFDAEhGRVFDAEhGRVOjGtHYRka5RbfLdEsencgLlOBSwJNVM23sVsCa6+1pgD/vqe46K5rYr99hh4P2+a11Q5TUe9F3rz5rQ1mmEac8LgAywlXBS1SnAmb5rpWlCWGmdlcAXCVeYqKhoAuUtpu29OuG2tZTS2qVrmLbnAC/7rnVVwbYpUZ1Q25m2dwlwkO9ay6L7bwJ84GBgdZxvz9KbTNszKfg3Ytre6wlnyD+IcEmTc33X+oVpe1cCv/Rd62tta2yC1MOSrmPa3krC2dzfCjwQzUBwLeHsCjuAD/qu9YRpe8cSzpaxKAp2hwCHRr8/77vWF6Lne9l3rRnR8Q7wAuE0UeuBs3zXypm2927CuQ63AQ8Ah/qutaioaQcDe9cm813riej5XeD1pu09AvzAd61PmLb3CWAxsB/wfd+1PhN9aN0Vve7bgMcIe4jbo+c4mXAdtHt81/p44++kdLAVwId91/qVaXvvIFyu5X8Szo6CaXsPEK475viudVf7mtlcSrqQbjUE/FnUm/kF8D+itZguA/65zGP+GPhrwuUyPmPa3tQSx7yVcJ2qwwmD2ztN29ufcDqsE33Xejvht95SbgQuNm1vrWl7/xgN30A408qvfdc6MgpWxxPOIXgUcCTwdtP2/iI69k3Al3zXOgx4CfhINCx6KvDmaB20f6z+9khambY3A/gzotlsCP/t5Zcz6eYJlNXDkq71Xd+19kS3DeCmKEDkgFKBCMCLJgveadrec8BrCCekLfQT37U2AkQfFibwMvBUNGEthFMPLS1+ct+1HjFt71DgeOA44CHT9o4h7PUVOj76eTi6P4PwQ+hZYIPvWg9E278FXAB8nrBHeYNpe6uB1WXOT7pDH7DVd60jS+zbCPyn71q7gKdN28tPoPxQKxuYFPWwpFttK7h9OfDDaPz/JMKhwVIKZ7bfQ+kvdHGOKct3rZd917rFd62PEAacd5c4LAP836jHdaTvWm/wXeuGaF/xRedcdI3uKMLFSBcRDhtKl/Jd6yXCYPReANP2MqbtvSXafSth74qUTaAciwKW9AKDfcs9fCCB538CODS6xgTwvlIHmbb3TtP2BqPbA4TDis8AvydcPiXvbuCcaOgH0/bmFGR7HRL1yiCcEf3H0XGG71p3AB8D3oJ0jVKT7wJ/ByyJJhN+jH0rPKdyAuW4NCQoveBKwiHBTwNNX63Yd60dpu19BLjLtL1tlB9+eT1wvWl7GcIvix7wvShp4wHT9h4F7oyuYx0GrDVtD8Ihx7MIe3RPAOdFtTmPA9cTBuTbomtpGcIVCKRL+K51Rpldk1akjmbAX0aX/htQWrtIE5i2N8N3rZejYHQd8CvftT7X5NcwUfq79DANCYo0x7lREsZjhD2er7S5PSJdRz0sERFJBfWwREQkFRSwREQkFRSwREQkFRSwREQkFRSwREQkFf4/0lzVKYNmx6oAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = make_env('PongNoFrameskip-v4')\n",
        "obs = env.reset()\n",
        "best_score = -np.inf # Reset best score\n",
        "load_checkpoint = False\n",
        "n_games = 500 # Number of games (episodes) to play \n",
        "n_steps = 0 # Number of time steps run till now\n",
        "scores = [] # Placeholder to store cumulative rewards for each episode (no discounting)\n",
        "steps_array = [] # Placeholder to store number of steps executed in each episode\n",
        "eps_history = [] # Placeholder to store epsilon value of agent at the end of each episode\n",
        "\n",
        "# Instantiate DQN agent\n",
        "agent = DQNAgent(gamma = 0.99, epsilon = 1, lr = 1e-4, input_dims = (env.observation_space.shape),\\\n",
        "                 n_actions = env.action_space.n, mem_size = 20000, eps_min = 0.1, batch_size = 32,\\\n",
        "                 replace = 1000, eps_dec = 1e-5, chkpt_dir = 'models/', algo = 'DQNAgent',\\\n",
        "                 env_name = 'PongNoFrameskip-v4')\n",
        "\n",
        "# Load saved model if load_checkpoint is true.\n",
        "if load_checkpoint:\n",
        "    agent.load_models()\n",
        "    \n",
        "for i in range(n_games): # Iterate through n_games (episodes)\n",
        "    done = False # Reset 'done' flag\n",
        "    observation = env.reset() # Reset environment at the start of the episode\n",
        "    score = 0 # Initialize score to 0.\n",
        "    while not done: # Loop till the end of the game (episode)\n",
        "        action = agent.choose_action(observation) # Choose action based on eps-greedy policy\n",
        "        observation_, reward, done, info = env.step(action) # Perform one step\n",
        "        score += reward # Increment score of current episode\n",
        "        if not load_checkpoint: # Update replay memory and perform one learning step\n",
        "            agent.store_transition(observation, action, reward, observation_, done)\n",
        "            agent.learn()\n",
        "        observation = observation_ # Replace current observation with next observation\n",
        "        n_steps += 1 # Update n_steps\n",
        "        #print(n_steps, end = \", \")\n",
        "    scores.append(score) # Update scores array at the end of current game\n",
        "    steps_array.append(n_steps) # Update steps array at the end of current game\n",
        "    eps_history.append(agent.epsilon) # Update eps_history\n",
        "    avg_score = np.mean(scores[-100:]) \n",
        "    print('episode: ', i,'score: ', score, ' average score %.1f' % avg_score, 'best score %.2f' % best_score,\\\n",
        "          'epsilon %.2f' % agent.epsilon, 'steps', n_steps)\n",
        "    if avg_score > best_score: # Update best_score if current episode score better than previous best_score\n",
        "        if not load_checkpoint:\n",
        "            #agent.save_models()\n",
        "            best_score = avg_score\n",
        "\n",
        "x = [i+1 for i in range(len(scores))]\n",
        "plot_learning_curve(steps_array, scores, eps_history)            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "261Ty7sAYXbo"
      },
      "source": [
        "# Backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLOdFLD_YXbp"
      },
      "source": [
        "## utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pUyoHtjqYXbp"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(x, scores, epsilons, filename=None, lines=None):\n",
        "    fig=plt.figure()\n",
        "    ax=fig.add_subplot(111, label=\"1\")\n",
        "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
        "\n",
        "    ax.plot(x, epsilons, color=\"C0\")\n",
        "    ax.set_xlabel(\"Training Steps\", color=\"C0\")\n",
        "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
        "    ax.tick_params(axis='x', colors=\"C0\")\n",
        "    ax.tick_params(axis='y', colors=\"C0\")\n",
        "\n",
        "    N = len(scores)\n",
        "    running_avg = np.empty(N)\n",
        "    for t in range(N):\n",
        "\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
        "\n",
        "    ax2.scatter(x, running_avg, color=\"C1\")\n",
        "    ax2.axes.get_xaxis().set_visible(False)\n",
        "    ax2.yaxis.tick_right()\n",
        "    ax2.set_ylabel('Score', color=\"C1\")\n",
        "    ax2.yaxis.set_label_position('right')\n",
        "    ax2.tick_params(axis='y', colors=\"C1\")\n",
        "\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            plt.axvline(x=line)\n",
        "\n",
        "    #plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUXEH_KcYXbp"
      },
      "source": [
        "## main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3459KMzMYXbp"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from dqn_agent import DQNAgent\n",
        "from utils import plot_learning_curve, make_env\n",
        "from gym import wrappers\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    env = make_env('PongNoFrameskip-v4')\n",
        "    #env = gym.make('CartPole-v1')\n",
        "    best_score = -np.inf\n",
        "    load_checkpoint = False\n",
        "    n_games = 250\n",
        "\n",
        "    agent = DQNAgent(gamma=0.99, epsilon=1, lr=0.0001,\n",
        "                     input_dims=(env.observation_space.shape),\n",
        "                     n_actions=env.action_space.n, mem_size=50000, eps_min=0.1,\n",
        "                     batch_size=32, replace=1000, eps_dec=1e-5,\n",
        "                     chkpt_dir='models/', algo='DQNAgent',\n",
        "                     env_name='PongNoFrameskip-v4')\n",
        "\n",
        "    if load_checkpoint:\n",
        "        agent.load_models()\n",
        "\n",
        "    fname = agent.algo + '_' + agent.env_name + '_lr' + str(agent.lr) +'_' \\\n",
        "            + str(n_games) + 'games'\n",
        "    figure_file = 'plots/' + fname + '.png'\n",
        "    # if you want to record video of your agent playing, do a mkdir tmp && mkdir tmp/dqn-video\n",
        "    # and uncomment the following 2 lines.\n",
        "    #env = wrappers.Monitor(env, \"tmp/dqn-video\",\n",
        "    #                    video_callable=lambda episode_id: True, force=True)\n",
        "    n_steps = 0\n",
        "    scores, eps_history, steps_array = [], [], []\n",
        "\n",
        "    for i in range(n_games):\n",
        "        done = False\n",
        "        observation = env.reset()\n",
        "\n",
        "        score = 0\n",
        "        while not done:\n",
        "            action = agent.choose_action(observation)\n",
        "            observation_, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "\n",
        "            if not load_checkpoint:\n",
        "                agent.store_transition(observation, action,\n",
        "                                     reward, observation_, done)\n",
        "                agent.learn()\n",
        "            observation = observation_\n",
        "            n_steps += 1\n",
        "        scores.append(score)\n",
        "        steps_array.append(n_steps)\n",
        "\n",
        "        avg_score = np.mean(scores[-100:])\n",
        "        print('episode: ', i,'score: ', score,\n",
        "             ' average score %.1f' % avg_score, 'best score %.2f' % best_score,\n",
        "            'epsilon %.2f' % agent.epsilon, 'steps', n_steps)\n",
        "\n",
        "        if avg_score > best_score:\n",
        "            if not load_checkpoint:\n",
        "                agent.save_models()\n",
        "            best_score = avg_score\n",
        "\n",
        "        eps_history.append(agent.epsilon)\n",
        "\n",
        "    x = [i+1 for i in range(len(scores))]\n",
        "    plot_learning_curve(steps_array, scores, eps_history, figure_file)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "307.2px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "DQN_Pong_Pytorch-checkpoint.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}